{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> SEE: Simple Evolutionary Exploration </center>\n",
    "\n",
    "<center>By Katrina Gensterblum</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/798/1*Zup7AqjAsHymZttgcKYLCw.jpeg\" width=\"80%\">\n",
    "<p style=\"text-align: right;\">Image from: https://miro.medium.com/</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Authors\n",
    "\n",
    "$\\text{Katrina Gensterblum}^{1}$, $\\text{Dirk Colbry}^{1}$, $\\text{Cameron Hurley}^{2}$, $\\text{Noah Stolz}^{3}$  \n",
    "\n",
    "$^{1}$ Department of Computational Mathematics, Science and Engineering, Michigan State University  \n",
    "$^{2}$ Department of Computer Science and Engineering, Michigan State University  \n",
    "$^{3}$ School of Science, School of Humanities and Social Sciences, Rensselaer Polytechnic Institute  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Abstract\n",
    "\n",
    "As the ability to collect image data increases, images are used more and more within a wide range of disciplines. However, processing this kind of data can be difficult and labor-intensive. One of the most time-consuming image processing techniques to perform is image segmentation. As a result, many image segmentation algorithms have been developed to try and accomplish this task automatically, but even finding the best algorithm for a dataset can be time intensive. Here we provide easy-to-use software that utilizes the power of genetic algorithms to automate the process of image segmentation. The software works to find both the best image segmentation algorithm for an image dataset, but also find the best hyperparameters for that segmentation algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Statement of Need\n",
    "\n",
    "As technology advances, image data is becoming a common element in a broad scope of research experiments. Studies in everything from self-driving vehicles to plant biology utilize images in some capacity. However, every image analysis problem is different and processing this kind of data and retrieving specific information can be extremely time-consuming. \n",
    "\n",
    "One of the main image processing techniques used today, and one of the most time-consuming, is image segmentation, which attempts to find entire objects within an image. As a way to try and make this process easier, many image processing algorithms have been developed to try and automatically segment an image. However, there are many different options available, and each algorithm may work best for a different image set. Additionally, many of these algorithms have hyperparameters that need to be tuned in order to get the most accurate results. So even if a researcher already possesses knowledge in image understanding and segmentation, it can be time-consuming to run and validate a customized solution for their problem. Thus, if this process could be automated, a significant amount of researcher time could be recovered.\n",
    "\n",
    "The purpose of the Simple Evolutionary Exploration, or SEE, software package is to provide an easy-to-use tool that can achieve this automation for image segmentation problems. By utilizing the power of genetic algorithms, the software can not only find the best image segmentation algorithm to use on an image set, but can also find the optimal parameters for that specific algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Installation Instructions\n",
    "\n",
    "A list of dependencies for SEE can be found in the [README](README.md) file.\n",
    "\n",
    "These dependencies can be installed individually, or by creating a conda environment using the command below:  \n",
    "\n",
    "**With makefile:**  `make init`  \n",
    "**Manually:**  `conda env create --prefix ./envs --file environment.yml`  \n",
    "  \n",
    "  ---\n",
    "In order to build automatic documentation for the project use one of the commands below:  \n",
    "\n",
    "**With makefile:**  `make doc`  \n",
    "**Manually:**  `pdoc --force --html --output-dir ./docs see`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Unit Tests\n",
    "\n",
    "Testing files for SEE can be found in `.\\see\\tests\\`. In order to run the tests run the cell below, or use one of the following commands:  \n",
    "\n",
    "**With makefile:** `make test`  \n",
    "**Manually:** `pytest -v see`  \n",
    "\n",
    "If the tests ran successfully, an output message should appear stating that $25$ tests were passed and $11$ warnings occurred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest -v see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Example Usage\n",
    "\n",
    "An example on how to use the `see` package and understand the results can be found in [HowToUse_Example.ipynb](HowToUse_Example.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Methodology\n",
    "\n",
    "In the original proposal there were three sets of goals: short term, midterm, and long term. The short term goals for this project included refining the output of the software, and the performance of the fitness function (or error function) of the algorithm used. Both of these goals were achieved within a few weeks of the proposal. The software now outputs usable code that can be copy-and-pasted into another script without the dependency of the SEE package. The fitness function was also found to have several bugs, all of which were fixed, and the function now runs as intended.  \n",
    "\n",
    "The first midterm goal was reached by the completion of this project. The goal was to package the code in a way that was usable by others. Throughout this project the code was organized and delinted, doc strings were added to functions, installation and run files were added, and documentation was added explaining the package and how to use it. By the end of the project timeline other students were testing the usability of the code and were able to successfully get it to work.\n",
    "\n",
    "The second midterm goal was to construct the search space that's used in the genetic algorithm, in a way that required as few distinct elements as possible. In order to achieve this goal, two additional search spaces were formed for a total of three search space options. The first search space that was tested was the original space. This took all hyperparameters used in the segmentation algorithms and generated a search space so that each hyperparameter got its own search space element. This gave good results and ran relatively quickly, but we wanted to see if the genetic algorithm could perform better with a smaller search space. That introduced the second search space that was tested. Since the first search space contained as many elements as possible, the second search space was made to contain as few elements as possible. The hyperparameters in the segmentation algorithms were combined in such a way that the number of elements in the search space could be reduced from around twenty elements to five elements. After running several tests, comparing the results from each of these options, we found that while the smaller search space required about 25% less computation time, it converged to a reasonable solution less often. \n",
    "\n",
    "This led us to create the third search space option. For this space, the elements were combined in a systematic way. Hyperparameters that were related were combined, and unique hyperparameters were left alone. This reduced the number of elements in the search space to twelve. While this seemed like a good medium between the two extreme search spaces, after running several tests, this search space actually performed the worst. It converged to a reasonable solution about as often as the small search space from before, but took longer than the original large search space. \n",
    "\n",
    "After looking at the results from all three search spaces, it turned out that the original search space still appeared to work the best. So while the goal of constructing new search spaces was reached, the original search space was kept in the algorithm.\n",
    "\n",
    "Of the long term goals for the project, one or two new segmentation algorithms were added, but the fitness function was not altered past the refining phase described in the short term goals. Since constructing the new search space ran into several issues, the extra goal has not been achieved yet. We are planning on refining the fitness function even more though, allowing for it to be more effective with problems where more than one object is being segmented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Concluding Remarks\n",
    "\n",
    "As stated above, most of the original project goals were reached. Along with achieving these goals, we learned how to package the code in a way that made it usable for others. Throughout the course of this project we learned how to incorporate different components that a professional package needs, including unit testing, delinting, and installation files. We also learned a lot about the importance of a flexible search space. The less flexible the search space, the harder it was for the genetic algorithm to find a good solution. \n",
    "\n",
    "In the future we plan to incorporate multi-image learning within our genetic algorithm. Currently, the algorithm just takes in a single training image in order to find a segmentation algorithm. This segmentation algorithm can then be applied to all images in the dataset. While this produces good results, with more data the genetic algorithm should be able to find a more general solution that will work better overall on all images in the data set. We also plan to expand the type of segmentation problem that the genetic algorithm can handle. While it can run on binary segmentation problems, problems where multiple objects need to be segmented out simultaneously have not been rigorously tested within our program. We also want to incorporate checkpointing and parallelization capabilities within the software as well. This will allow the program to run longer and more involved experiments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# References\n",
    "\n",
    "The GitHub repository for SEE can be found [here](https://github.com/genster6/Simple-Evolutionary-Exploration.git). \n",
    "\n",
    "[\\[1\\]](https://www.ime.usp.br/~eduardob/datasets/sky/) Alexandre, Eduardo B., et al. IFT-SLIC: Geração de Superpixels com Base em Agrupamento Iterativo Linear Simples e Transformada Imagem-Floresta. Master dissertation, IME - USP.  \n",
    "\n",
    "[\\[2\\]](http://cocodataset.org/#download) Lin, Tsung-Yi, et al. “Microsoft COCO: Common Objects in Context.” Computer Vision – ECCV 2014 Lecture Notes in Computer Science, 2014, pp. 740–755.  \n",
    "\n",
    "[\\[3\\]](https://peerj.com/articles/453/) Walt, Stéfan Van Der, et al. “Scikit-Image: Image Processing in Python.” PeerJ, vol. 2, 2014.  \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
