<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>see.Segmentors API documentation</title>
<meta name="description" content="Segmentor algorithm library designed to segment images with a searchable parameter space.
This libary actually does not incode the search code itself, …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>see.Segmentors</code></h1>
</header>
<section id="section-intro">
<p>Segmentor algorithm library designed to segment images with a searchable parameter space.
This libary actually does not incode the search code itself, instead it just defines
the search parameters and the evaluation funtions.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Segmentor algorithm library designed to segment images with a searchable parameter space.
 This libary actually does not incode the search code itself, instead it just defines
  the search parameters and the evaluation funtions.&#34;&#34;&#34;

import copy
import inspect
import random

from collections import OrderedDict
import sys
import logging
import numpy as np
import skimage
from skimage import segmentation
from skimage import color

from see.base_classes import param_space, algorithm


class seg_params(param_space):
    descriptions = dict()
    ranges = dict()
    pkeys = []


seg_params.add(&#39;algorithm&#39;,
               [],
               &#34;string code for the algorithm&#34;)

seg_params.add(&#39;alpha1&#39;,
               [float(i)/256 for i in range(0, 256)],
               &#34;General Purpos Lower bound threshold&#34;
               )

seg_params.add(&#39;alpha2&#39;,
               [float(i)/256 for i in range(0, 256)],
               &#34;General Purpos Upper bound threshold&#34;
               )

seg_params.add(&#39;beta1&#39;,
               [float(i)/256 for i in range(0, 256)],
               &#34;General Purpos Lower bound threshold&#34;
               )

seg_params.add(&#39;beta2&#39;,
               [float(i)/256 for i in range(0, 256)],
               &#34;General Purpos Upper bound threshold&#34;
               )

seg_params.add(&#39;gamma1&#39;,
               [float(i)/256 for i in range(0, 256)],
               &#34;General Purpos Lower bound threshold&#34;
               )

seg_params.add(&#39;gamma2&#39;,
               [float(i)/256 for i in range(0, 256)],
               &#34;General Purpos Upper bound threshold&#34;
               )

seg_params.add(&#39;n_segments&#39;,
               [i for i in range(0, 10)],
               &#34;General Purpos Upper bound threshold&#34;
               )

seg_params.add(&#39;max_iter&#39;,
               [i for i in range(1, 20)],
               &#34;General Purpos Upper bound threshold&#34;
               )


class segmentor(algorithm):
    &#34;&#34;&#34;Base class for segmentor classes defined below.

    Functions:
    evaluate -- Run segmentation algorithm to get inferred mask.

    &#34;&#34;&#34;

    algorithmspace = dict()

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Generate algorithm params from parameter list.&#34;&#34;&#34;
        #super(ColorThreshold, self).__init__(paramlist)
        self.params = seg_params()

        self.params[&#39;algorithm&#39;] = &#39;ColorThreshold&#39;
        self.params[&#39;alpha1&#39;] = 0.3
        self.params[&#39;alpha2&#39;] = 0.5
        self.params[&#39;beta1&#39;] = 0.2
        self.params[&#39;beta2&#39;] = 0.7
        self.params[&#39;gamma1&#39;] = 0.3
        self.params[&#39;gamma2&#39;] = 0.5
        self.params[&#39;n_segments&#39;] = 2
        self.params[&#39;max_iter&#39;] = 10
        self.set_params(paramlist)

        
    # TODO use name to build a dictionary to use as a chache
    def evaluate(self, img):
        &#34;&#34;&#34;Run segmentation algorithm to get inferred mask.&#34;&#34;&#34;
        import sys

        #print(f&#34;Running {self.params}&#34;)
        sys.stdout.flush()
        self.thisalgo = segmentor.algorithmspace[self.params[&#39;algorithm&#39;]](self.params)
        return self.thisalgo.evaluate(img)

    def pipe(self, data):
        data.mask = self.evaluate(data.img)
        return data

    @classmethod
    def addsegmentor(cls, key, seg):
        seg_params.ranges[&#39;algorithm&#39;].append(key)
        cls.algorithmspace[key] = seg


class ColorThreshold(segmentor):
    &#34;&#34;&#34;ColorThreshold

    Peform Color Thresholding segmentation algorithm. Segments parts of the image
    based on the numerical values for the respective channel.

    Parameters:
    mulitchannel - (multichannel) - bool, Whether the image is 2D or 3D
    colorspace - (colorspace) Select the colorspace [‘RGB’, ‘HSV’, ‘RGB CIE’, ‘XYZ’, ‘YUV’, ‘YIQ’, ‘YPbPr’, ‘YCbCr’, ‘YDbDr’]
    channel - (channel) color chanel (0:R/H/L 1:G/S/A, 2:B/V/B)
    ch0_mn - (alpha1) - minimum thresholding value for channel 0
    ch0_mx - (alpha2) - maximum thresholding value for channel 0
    ch1_mn - (beta1) - minimum thresholding value for channel 1
    ch1_mx - (beta2) - maximum thresholding value for channel 1
    ch2_mn - (gamma1) - minimum thresholding value for channel 2
    ch2_mx - (gamma2) - maximum thresholding value for channel 2

    Note: a colorspace of &#39;HSV&#39; and a channel of 2 is a grayscale image. 

    Typically any pixel between my_mn and my_mx are true. Other pixels are false.

    if my_mn &gt; my_mx then the logic flips and anything above my_mn and below my_mx are true. 
    The pixels between the valuse are false
    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        self.params = seg_params()

        self.params[&#34;algorithm&#34;] = &#34;ColorThreshold&#34;
        self.params[&#34;alpha1&#34;] = 0.4
        self.params[&#34;alpha2&#34;] = 0.6
        self.params[&#34;beta1&#34;] = 0.4
        self.params[&#34;beta2&#34;] = 0.6
        self.params[&#34;gamma1&#34;] = 0.4
        self.params[&#34;gamma2&#34;] = 0.6
        self.paramindexes = [&#34;alpha1&#34;, &#34;alpha2&#34;,
                             &#34;beta1&#34;, &#34;beta2&#34;,
                             &#34;gamma1&#34;, &#34;gamma2&#34;]
        #print(f&#34;colorthreshold.paramlist = {paramlist}&#34;)
        self.set_params(paramlist)
        #print(f&#34;_init_.self.params={self.params}&#34;)
          


    def evaluate(self, img):  # XX
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;
        minlist = [&#34;alpha1&#34;, &#34;beta1&#34;, &#34;gamma1&#34;]
        maxlist = [&#34;alpha2&#34;, &#34;beta2&#34;, &#34;gamma2&#34;]

        output = None

        #print(f&#34;self.params={self.params}&#34;)
        if (len(img.shape) &gt; 2):
            output = np.ones([img.shape[0], img.shape[1]])
            for dimidx in range(3):
                pscale = np.max(img[:, :, dimidx])
                my_mn = float(self.params[minlist[dimidx]]) * pscale
                my_mx = float(self.params[maxlist[dimidx]])  * pscale

                if my_mn &lt; my_mx:
                    output[img[:, :, dimidx] &lt; my_mn] = 0
                    output[img[:, :, dimidx] &gt; my_mx] = 0
                else:
                    flag1 = img[:, :, dimidx] &gt; my_mn
                    flag2 = img[:, :, dimidx] &lt; my_mx
                    output[np.logical_and(flag1, flag2)] = 0
        else:
            pscale = np.max(img)
            chidx = 0
            if &#34;channel&#34; in self.params:
                chidx = self.params[&#34;channel&#34;]
            my_mn = float(self.params[minlist[chidx]]) * pscale
            my_mx = float(self.params[maxlist[chidx]]) * pscale


            if my_mn &lt; my_mx:
                output = np.ones(img.shape)
                output[img &lt; my_mn] = 0
                output[img &gt; my_mx] = 0
            else:
                output = np.zeros(img.shape)
                output[img &gt; my_mn] = 1
                output[img &lt; my_mx] = 1
        return output


segmentor.addsegmentor(&#39;ColorThreshold&#39;, ColorThreshold)


class Felzenszwalb(segmentor):
    &#34;&#34;&#34;Perform Felzenszwalb segmentation algorithm. The felzenszwalb algorithms computes a 
    graph based on the segmentation. Produces an oversegmentation of the multichannel using 
    min-span tree. Returns an integer mask indicating the segment labels.

    Note: a colorspace of &#39;HSV&#39; and a channel of 2 is a grayscale image. 

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.felzenszwalb

    Parameters:
    colorspace - (colorspace) Select the colorspace (0:RGB, 1:HSV, 2:LAB)
    channel - (channel) color chanel (0:R/H/L 1:G/S/A, 2:B/V/B)
    scale - (alpha2*1000) - float, higher meanse larger clusters
    sigma - (alpha1) - float, std. dev of Gaussian kernel for preprocessing
    min_size - int(beta1*100) - int, minimum component size (in pixels). For postprocessing
    &#34;&#34;&#34;

#     def __doc__(self):
#         &#34;&#34;&#34;Return help string for function.&#34;&#34;&#34;
#         myhelp = &#34;Wrapper function for the scikit-image Felzenszwalb segmentor:&#34;
#         myhelp += f&#34; xx {skimage.segmentation.random_walker.__doc__}&#34;
#         return myhelp

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Felzenszwalb, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Felzenszwalb&#34;
        self.params[&#34;alpha2&#34;] = 0.984
        self.params[&#34;alpha1&#34;] = 0.09
        self.params[&#34;beta1&#34;] = 0.92
        self.paramindexes = [&#34;alpha1&#34;, &#34;alpha2&#34;, &#34;beta1&#34;]
        self.set_params(paramlist)
                
    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        scale = self.params[&#34;alpha2&#34;]*1000
        sigma = self.params[&#34;alpha1&#34;]
        min_size = int(self.params[&#34;beta1&#34;]*100)

        if (len(img.shape) &gt; 2):
            output = skimage.segmentation.felzenszwalb(
                img,
                scale,
                sigma,
                min_size,
                multichannel=True
            )
        else:
            output = skimage.segmentation.felzenszwalb(
                img,
                scale,
                sigma,
                min_size,
                multichannel=False
            )

        return output

#     def sharepython(self, img):


#         multichannel = self.params[&#39;multichannel&#39;]
#         if len(img.shape) == 1:
#             multichannel = False
#         if (multichannel):
#             mystring= f&#34;&#34;&#34;
#             output = skimage.segmentation.felzenszwalb(
#                 img,
#                 {self.params[&#34;alpha2&#34;]*1000},
#                 {self.params[&#34;alpha1&#34;]},
#                 {int(self.params[&#34;beta1&#34;]*100)},
#                 multichannel={multichannel}
#             )&#34;&#34;&#34;
#         else:
#             mystring= f&#34;&#34;&#34;
#             output = skimage.segmentation.felzenszwalb(
#                 getchannel(img, {self.params[&#34;channel&#34;]}),
#                 {self.params[&#34;alpha2&#34;]*1000},
#                 {self.params[&#34;alpha1&#34;]},
#                 {int(self.params[&#34;beta1&#34;]*100)},
#                 multichannel={multichannel}
#             )&#34;&#34;&#34;
#         return mystring

segmentor.addsegmentor(&#39;Felzenszwalb&#39;, Felzenszwalb)


class Slic(segmentor):
    &#34;&#34;&#34;Perform the Slic segmentation algorithm. Segments k-means clustering in Color space
     (x, y, z). Returns a 2D or 3D array of labels.

    Parameters:
    image -- ndarray, input image
    n_segments -- int, approximate number of labels in segmented output image
    compactness -- float, Balances color proximity and space proximity.
        Higher values mean more weight to space proximity (superpixels
        become more square/cubic) Recommended log scale values (0.01,
        0.1, 1, 10, 100, etc)
    max_iter -- int, max number of iterations of k-means
    sigma -- float or (3,) shape array of floats, width of Guassian
        smoothing kernel. For pre-processing for each dimesion of the
        image. Zero means no smoothing.
    spacing -- (3,) shape float array. Voxel spacing along each image
        dimension. Defalt is uniform spacing
    multichannel -- bool,  multichannel (True) vs grayscale (False)

    enforce_connectivity

   https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic

   https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/


    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Slic, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Slic&#34;
        self.params[&#34;n_segments&#34;] = 5
        self.params[&#34;beta1&#34;] = 2
        self.params[&#34;max_iter&#34;] = 10
        self.params[&#34;alpha1&#34;] = 0.5
        self.paramindexes = [&#34;n_segments&#34;, &#34;alpha1&#34;, &#34;beta1&#34;, &#34;max_iter&#34;]
        self.slico = False
        self.set_params(paramlist)
                
    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        compactness = 10**(self.params[&#34;beta1&#34;]*3-3)
        n_segments = self.params[&#34;n_segments&#34;]+1
        max_iter = self.params[&#34;max_iter&#34;]
        if (len(img.shape) &gt; 2):
            output = skimage.segmentation.slic(
                img,
                n_segments=n_segments,
                compactness=compactness,
                max_iter=max_iter,
                # Gaussian smoothing should happen as a preprocessing step.
                sigma=0,
                convert2lab=False,
                multichannel=True,
                slic_zero=self.slico
            )
        else:
            output = skimage.segmentation.slic(
                img,
                n_segments=n_segments,
                compactness=compactness,
                max_iter=max_iter,
                sigma=self.params[&#34;alpha1&#34;],
                multichannel=False,
                slic_zero=self.slico
            )
        return output


segmentor.addsegmentor(&#39;Slic&#39;, Slic)

# TODO Update to remove any parameters that SLICO dosn&#39;t use. (Currently this includes the SLIP parameters)


class SlicO(Slic):
    &#34;&#34;&#34;Perform the SlicO segmentation algorithm. Segments k-means clustering in Color space
     (x, y, z). Returns a 2D or 3D array of labels.

    Parameters:
    image -- ndarray, input image
    n_segments -- int, approximate number of labels in segmented output image
    compactness -- float, Balances color proximity and space proximity.
        Higher values mean more weight to space proximity (superpixels
        become more square/cubic) Recommended log scale values (0.01,
        0.1, 1, 10, 100, etc)
    max_iter -- int, max number of iterations of k-means
    sigma -- float or (3,) shape array of floats, width of Guassian
        smoothing kernel. For pre-processing for each dimesion of the
        image. Zero means no smoothing.
    spacing -- (3,) shape float array. Voxel spacing along each image
        dimension. Defalt is uniform spacing
    multichannel -- bool,  multichannel (True) vs grayscale (False)

    enforce_connectivity

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic

    https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/


    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(SlicO, self).__init__(paramlist)
        self.slico = True
        self.set_params(paramlist)

segmentor.addsegmentor(&#39;SlicO&#39;, SlicO)

# TODO Quickshift is very slow, we need to do some benchmarks and see what are resonable running ranges.


class QuickShift(segmentor):
    &#34;&#34;&#34;Perform the Quick Shift segmentation algorithm. Segments images with quickshift
     clustering in Color (x,y) space. Returns ndarray segmentation mask of the labels.

    Parameters:
    image -- ndarray, input image
    ratio -- float, balances color-space proximity &amp; image-space
        proximity. Higher vals give more weight to color-space
    kernel_size: float, Width of Guassian kernel using smoothing.
        Higher means fewer clusters
    max_dist -- float, Cut-off point for data distances. Higher means fewer clusters
    sigma -- float, Width of Guassian smoothing as preprocessing.
        Zero means no smoothing
    random_seed -- int, Random seed used for breacking ties.

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.quickshift

    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(QuickShift, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;QuickShift&#34;
        self.params[&#34;alpha1&#34;] = 0.5
        self.params[&#34;beta1&#34;] = 0.5
        self.params[&#34;beta2&#34;] = 0.5
        self.paramindexes = [&#34;alpha1&#34;, &#34;beta1&#34;, &#34;beta2&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        mindim = min(img.shape)
        ratio = self.params[&#34;alpha1&#34;]
        kernel_size = mindim/10*self.params[&#34;beta1&#34;]+1
        max_dist = mindim*self.params[&#34;beta2&#34;]
        output = skimage.segmentation.quickshift(
            img,
            ratio=ratio,
            kernel_size=kernel_size,
            max_dist=max_dist,
            sigma=0,  # TODO this should be handeled in the preprocessing step
            random_seed=1,
            convert2lab=False
        )
        return output


segmentor.addsegmentor(&#39;QuickShift&#39;, QuickShift)

# TODO Watershed one seems to be broken all we get is a line at the top.


class Watershed(segmentor):
    &#34;&#34;&#34;Perform the Watershed segmentation algorithm. Uses user-markers.
     treats markers as basins and &#39;floods&#39; them. Especially good if overlapping objects.
      Returns a labeled image ndarray.

    Parameters:
    image -- ndarray, input array
    compactness -- float, compactness of the basins. Higher values
        make more regularly-shaped basin.

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.watershed

    &#34;&#34;&#34;

    # Not using connectivity, markers, or offset params as arrays would
    # expand the search space too much.
    # abbreviation for algorithm = WS

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Watershed, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Watershed&#34;
        self.params[&#34;alpha1&#34;] = 0.66
        self.paramindexes = [&#34;alpha1&#34;]
        self.set_params(paramlist)
                
    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.



        &#34;&#34;&#34;

        compactness = self.params[&#34;alpha1&#34;]*3

        output = skimage.segmentation.watershed(
            img, markers=None, compactness=compactness
        )
        return output


segmentor.addsegmentor(&#39;Watershed&#39;, Watershed)

# TODO Chan_Vese one seems very broken.  All we get is a circle.


class Chan_Vese(segmentor):
    &#34;&#34;&#34;Peform Chan Vese segmentation algorithm. ONLY GRAYSCALE. Segments objects
     without clear boundaries. Returns segmentation array of algorithm.

    Parameters:
    image -- ndarray grayscale image to be segmented
    mu -- float, &#39;edge length&#39; weight parameter. Higher mu vals make a
        &#39;round edge&#39; closer to zero will detect smaller objects. Typical
        values are from 0 - 1.
    lambda1 -- float &#39;diff from average&#39; weight param to determine if
        output region is True. If lower than lambda1, the region has a
        larger range of values than the other
    lambda2 -- float &#39;diff from average&#39; weight param to determine if
        output region is False. If lower than lambda1, the region will
        have a larger range of values
    tol -- positive float, typically (0-1), very low level set variation
        tolerance between iterations.
    max_iter -- uint,  max number of iterations before algorithms stops
    dt -- float, Multiplication factor applied at the calculations step



    &#34;&#34;&#34;

    # Abbreviation for Algorithm = CV

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Chan_Vese, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Chan_Vese&#34;
        self.params[&#34;alpha1&#34;] = 1
        self.params[&#34;beta1&#34;] = 1
        self.params[&#34;beta2&#34;] = 1
        self.params[&#34;max_iter&#34;] = 10
        self.params[&#34;alpha2&#34;] = 0.10
        self.params[&#34;n_segments&#34;] = 0
        # self.params[&#34;tolerance&#34;] = 0.001 #TODO Removed, consider adding in later if need be.
        self.paramindexes = [&#34;alpha1&#34;, &#34;alpha2&#34;,
                             &#34;beta1&#34;, &#34;beta2&#34;, &#34;n_segments&#34;, &#34;max_iter&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        # TODO I think this should be between zero and one.
        mu = self.params[&#34;alpha1&#34;]*2
        # TODO Not sure about the range of these. Previous was (10,20)
        lambda1 = self.params[&#34;beta1&#34;]
        lambda2 = self.params[&#34;beta2&#34;]
        max_iter = self.params[&#34;max_iter&#34;]
        dt = self.params[&#34;alpha2&#34;]

        level_set_shapes = [&#39;checkerboard&#39;, &#39;disk&#39;, &#39;small disk&#39;]
        init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 3]

        if(len(img.shape) &gt; 2):
            if &#34;channel&#34; in self.params:
                channel = self.params[&#39;channel&#39;]
                img = img[:, :, channel]
            else:
                img = color.rgb2gray(img)

        output = skimage.segmentation.chan_vese(
            img,
            mu=mu,
            lambda1=lambda1,
            lambda2=lambda2,
            max_iter=max_iter,
            dt=dt,
            init_level_set=init_level_set

        )
        return output


segmentor.addsegmentor(&#39;Chan_Vese&#39;, Chan_Vese)


class Morphological_Chan_Vese(segmentor):
    &#34;&#34;&#34;Peform Morphological Chan Vese segmentation algorithm.
     ONLY WORKS ON GRAYSCALE. Active contours without edges. Can be used to
      segment images/volumes without good borders. Required that the inside of
       the object looks different than outside (color, shade, darker).

    Parameters:
    image -- ndarray of grayscale image
    iterations -- uint, number of iterations to run
    init_level_set -- str, or array same shape as image. Accepted string
        values are:
        &#39;checkerboard&#39;: Uses checkerboard_level_set. Returns a binary level set of a checkerboard
        &#39;circle&#39;: Uses circle_level_set. Creates a binary level set of a circle, given radius and a
            center
    smoothing -- uint, number of times the smoothing operator is applied
        per iteration. Usually around 1-4. Larger values make it smoother
    lambda1 -- Weight param for outer region. If larger than lambda2,
        outer region will give larger range of values than inner value.
    lambda2 -- Weight param for inner region. If larger thant lambda1,
        inner region will have a larger range of values than outer region.

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_chan_vese

    &#34;&#34;&#34;

    # Abbreviation for algorithm = MCV

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Morphological_Chan_Vese, self).__init__(paramlist)
        if not paramlist:
            self.params[&#34;algorithm&#34;] = &#34;Morphological_Chan_Vese&#34;
            self.params[&#34;alpha1&#34;] = 1
            self.params[&#34;beta1&#34;] = 1
            self.params[&#34;beta2&#34;] = 1
            self.params[&#34;max_iter&#34;] = 10
            self.params[&#34;n_segments&#34;] = 0
            # self.params[&#34;tolerance&#34;] = 0.001 #TODO Removed, consider adding in later if need be.
        self.paramindexes = [&#34;alpha1&#34;,  &#34;beta1&#34;,
                             &#34;beta2&#34;, &#34;n_segments&#34;, &#34;max_iter&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        # TODO We may want to move this? We need a number 1-4 smoothing iterations
        smoothing = int(self.params[&#34;alpha1&#34;]*4)

        # TODO Not sure about the range of these. Previous was (10,20)
        lambda1 = self.params[&#34;beta1&#34;]
        lambda2 = self.params[&#34;beta2&#34;]
        max_iter = self.params[&#34;max_iter&#34;]
        level_set_shapes = [&#39;checkerboard&#39;, &#39;circle&#39;]
        init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 2]

        if(len(img.shape) &gt; 2):
            if &#34;channel&#34; in self.params:
                channel = self.params[&#39;channel&#39;]
                img = img[:, :, channel]
            else:
                img = color.rgb2gray(img)

        output = skimage.segmentation.morphological_chan_vese(
            img,
            iterations=max_iter,
            init_level_set=init_level_set,
            smoothing=smoothing,
            lambda1=lambda1,
            lambda2=lambda2,
        )
        return output


segmentor.addsegmentor(&#39;Morphological_Chan_Vese&#39;, Morphological_Chan_Vese)


class MorphGeodesicActiveContour(segmentor):
    &#34;&#34;&#34;Peform Morphological Geodesic Active Contour segmentation algorithm. Uses
     an image from inverse_gaussian_gradient in order to segment object with visible,
      but noisy/broken borders. inverse_gaussian_gradient computes the magnitude of
       the gradients in an image. Returns a preprocessed image suitable for above function.
        Returns ndarray of segmented image.

    Parameters:
    gimage -- array, preprocessed image to be segmented.
    iterations -- uint, number of iterations to run.
    init_level_set -- str, array same shape as gimage. If string, possible
        values are:
        &#39;checkerboard&#39;: Uses checkerboard_level_set. Returns a binary level set of a checkerboard
        &#39;circle&#39;: Uses circle_level_set. Creates a binary level set of a circle, given radius and a
            center
    smoothing -- uint, number of times the smoothing operator is applied
        per iteration. Usually 1-4, larger values have smoother segmentation.
    threshold -- Areas of image with a smaller value than the threshold are borders.
    balloon -- float, guides contour of low-information parts of image.

    morphological_geodesic_active_contour
    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_geodesic_active_contour

    Preprocessign step:
    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.inverse_gaussian_gradient


    &#34;&#34;&#34;

    # Abbrevieation for algorithm = AC

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(MorphGeodesicActiveContour, self).__init__(paramlist)
        if not paramlist:
            self.params[&#34;algorithm&#34;] = &#34;MorphGeodesicActiveContour&#34;
            self.params[&#34;alpha1&#34;] = 1
            self.params[&#34;alpha2&#34;] = 1
            self.params[&#34;beta1&#34;] = 0.2
            self.params[&#34;beta2&#34;] = 0.3
            self.params[&#34;beta2&#34;] = 1
            self.params[&#34;max_iter&#34;] = 10
            self.params[&#34;n_segments&#34;] = 0
            # self.params[&#34;tolerance&#34;] = 0.001 #TODO Removed, consider adding in later if need be.
        self.paramindexes = [&#34;alpha1&#34;,  &#34;alpha2&#34;,
                             &#34;beta1&#34;, &#34;beta2&#34;, &#34;n_segments&#34;, &#34;max_iter&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        # TODO We may want to move this? We need a number 1-4 smoothing iterations
        smoothing = int(self.params[&#34;alpha1&#34;]*4)
        balloon = (self.params[&#34;alpha2&#34;]*100)-50
        max_iter = self.params[&#34;max_iter&#34;]
        level_set_shapes = [&#39;checkerboard&#39;, &#39;circle&#39;]
        init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 2]

        if(len(img.shape) &gt; 2):
            if &#34;channel&#34; in self.params:
                channel = self.params[&#39;channel&#39;]
                img = img[:, :, channel]
            else:
                img = color.rgb2gray(img)

        # We run the inverse_gaussian_gradient to get the image to use
        gimage = skimage.segmentation.inverse_gaussian_gradient(
            img, self.params[&#34;beta1&#34;], self.params[&#34;beta2&#34;]
        )
        # zeros = 0
        output = skimage.segmentation.morphological_geodesic_active_contour(
            gimage,
            max_iter,
            init_level_set,
            smoothing,
            threshold=&#34;auto&#34;,
            balloon=balloon,
        )
        return output


segmentor.addsegmentor(&#39;MorphGeodesicActiveContour&#39;,
                       MorphGeodesicActiveContour)


##########################</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="see.Segmentors.Chan_Vese"><code class="flex name class">
<span>class <span class="ident">Chan_Vese</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Peform Chan Vese segmentation algorithm. ONLY GRAYSCALE. Segments objects
without clear boundaries. Returns segmentation array of algorithm.</p>
<p>Parameters:
image &ndash; ndarray grayscale image to be segmented
mu &ndash; float, 'edge length' weight parameter. Higher mu vals make a
'round edge' closer to zero will detect smaller objects. Typical
values are from 0 - 1.
lambda1 &ndash; float 'diff from average' weight param to determine if
output region is True. If lower than lambda1, the region has a
larger range of values than the other
lambda2 &ndash; float 'diff from average' weight param to determine if
output region is False. If lower than lambda1, the region will
have a larger range of values
tol &ndash; positive float, typically (0-1), very low level set variation
tolerance between iterations.
max_iter &ndash; uint,
max number of iterations before algorithms stops
dt &ndash; float, Multiplication factor applied at the calculations step</p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Chan_Vese(segmentor):
    &#34;&#34;&#34;Peform Chan Vese segmentation algorithm. ONLY GRAYSCALE. Segments objects
     without clear boundaries. Returns segmentation array of algorithm.

    Parameters:
    image -- ndarray grayscale image to be segmented
    mu -- float, &#39;edge length&#39; weight parameter. Higher mu vals make a
        &#39;round edge&#39; closer to zero will detect smaller objects. Typical
        values are from 0 - 1.
    lambda1 -- float &#39;diff from average&#39; weight param to determine if
        output region is True. If lower than lambda1, the region has a
        larger range of values than the other
    lambda2 -- float &#39;diff from average&#39; weight param to determine if
        output region is False. If lower than lambda1, the region will
        have a larger range of values
    tol -- positive float, typically (0-1), very low level set variation
        tolerance between iterations.
    max_iter -- uint,  max number of iterations before algorithms stops
    dt -- float, Multiplication factor applied at the calculations step



    &#34;&#34;&#34;

    # Abbreviation for Algorithm = CV

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Chan_Vese, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Chan_Vese&#34;
        self.params[&#34;alpha1&#34;] = 1
        self.params[&#34;beta1&#34;] = 1
        self.params[&#34;beta2&#34;] = 1
        self.params[&#34;max_iter&#34;] = 10
        self.params[&#34;alpha2&#34;] = 0.10
        self.params[&#34;n_segments&#34;] = 0
        # self.params[&#34;tolerance&#34;] = 0.001 #TODO Removed, consider adding in later if need be.
        self.paramindexes = [&#34;alpha1&#34;, &#34;alpha2&#34;,
                             &#34;beta1&#34;, &#34;beta2&#34;, &#34;n_segments&#34;, &#34;max_iter&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        # TODO I think this should be between zero and one.
        mu = self.params[&#34;alpha1&#34;]*2
        # TODO Not sure about the range of these. Previous was (10,20)
        lambda1 = self.params[&#34;beta1&#34;]
        lambda2 = self.params[&#34;beta2&#34;]
        max_iter = self.params[&#34;max_iter&#34;]
        dt = self.params[&#34;alpha2&#34;]

        level_set_shapes = [&#39;checkerboard&#39;, &#39;disk&#39;, &#39;small disk&#39;]
        init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 3]

        if(len(img.shape) &gt; 2):
            if &#34;channel&#34; in self.params:
                channel = self.params[&#39;channel&#39;]
                img = img[:, :, channel]
            else:
                img = color.rgb2gray(img)

        output = skimage.segmentation.chan_vese(
            img,
            mu=mu,
            lambda1=lambda1,
            lambda2=lambda2,
            max_iter=max_iter,
            dt=dt,
            init_level_set=init_level_set

        )
        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.Chan_Vese.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.

    &#34;&#34;&#34;

    # TODO I think this should be between zero and one.
    mu = self.params[&#34;alpha1&#34;]*2
    # TODO Not sure about the range of these. Previous was (10,20)
    lambda1 = self.params[&#34;beta1&#34;]
    lambda2 = self.params[&#34;beta2&#34;]
    max_iter = self.params[&#34;max_iter&#34;]
    dt = self.params[&#34;alpha2&#34;]

    level_set_shapes = [&#39;checkerboard&#39;, &#39;disk&#39;, &#39;small disk&#39;]
    init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 3]

    if(len(img.shape) &gt; 2):
        if &#34;channel&#34; in self.params:
            channel = self.params[&#39;channel&#39;]
            img = img[:, :, channel]
        else:
            img = color.rgb2gray(img)

    output = skimage.segmentation.chan_vese(
        img,
        mu=mu,
        lambda1=lambda1,
        lambda2=lambda2,
        max_iter=max_iter,
        dt=dt,
        init_level_set=init_level_set

    )
    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.ColorThreshold"><code class="flex name class">
<span>class <span class="ident">ColorThreshold</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>ColorThreshold</p>
<p>Peform Color Thresholding segmentation algorithm. Segments parts of the image
based on the numerical values for the respective channel.</p>
<p>Parameters:
mulitchannel - (multichannel) - bool, Whether the image is 2D or 3D
colorspace - (colorspace) Select the colorspace [‘RGB’, ‘HSV’, ‘RGB CIE’, ‘XYZ’, ‘YUV’, ‘YIQ’, ‘YPbPr’, ‘YCbCr’, ‘YDbDr’]
channel - (channel) color chanel (0:R/H/L 1:G/S/A, 2:B/V/B)
ch0_mn - (alpha1) - minimum thresholding value for channel 0
ch0_mx - (alpha2) - maximum thresholding value for channel 0
ch1_mn - (beta1) - minimum thresholding value for channel 1
ch1_mx - (beta2) - maximum thresholding value for channel 1
ch2_mn - (gamma1) - minimum thresholding value for channel 2
ch2_mx - (gamma2) - maximum thresholding value for channel 2</p>
<p>Note: a colorspace of 'HSV' and a channel of 2 is a grayscale image. </p>
<p>Typically any pixel between my_mn and my_mx are true. Other pixels are false.</p>
<p>if my_mn &gt; my_mx then the logic flips and anything above my_mn and below my_mx are true.
The pixels between the valuse are false</p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ColorThreshold(segmentor):
    &#34;&#34;&#34;ColorThreshold

    Peform Color Thresholding segmentation algorithm. Segments parts of the image
    based on the numerical values for the respective channel.

    Parameters:
    mulitchannel - (multichannel) - bool, Whether the image is 2D or 3D
    colorspace - (colorspace) Select the colorspace [‘RGB’, ‘HSV’, ‘RGB CIE’, ‘XYZ’, ‘YUV’, ‘YIQ’, ‘YPbPr’, ‘YCbCr’, ‘YDbDr’]
    channel - (channel) color chanel (0:R/H/L 1:G/S/A, 2:B/V/B)
    ch0_mn - (alpha1) - minimum thresholding value for channel 0
    ch0_mx - (alpha2) - maximum thresholding value for channel 0
    ch1_mn - (beta1) - minimum thresholding value for channel 1
    ch1_mx - (beta2) - maximum thresholding value for channel 1
    ch2_mn - (gamma1) - minimum thresholding value for channel 2
    ch2_mx - (gamma2) - maximum thresholding value for channel 2

    Note: a colorspace of &#39;HSV&#39; and a channel of 2 is a grayscale image. 

    Typically any pixel between my_mn and my_mx are true. Other pixels are false.

    if my_mn &gt; my_mx then the logic flips and anything above my_mn and below my_mx are true. 
    The pixels between the valuse are false
    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        self.params = seg_params()

        self.params[&#34;algorithm&#34;] = &#34;ColorThreshold&#34;
        self.params[&#34;alpha1&#34;] = 0.4
        self.params[&#34;alpha2&#34;] = 0.6
        self.params[&#34;beta1&#34;] = 0.4
        self.params[&#34;beta2&#34;] = 0.6
        self.params[&#34;gamma1&#34;] = 0.4
        self.params[&#34;gamma2&#34;] = 0.6
        self.paramindexes = [&#34;alpha1&#34;, &#34;alpha2&#34;,
                             &#34;beta1&#34;, &#34;beta2&#34;,
                             &#34;gamma1&#34;, &#34;gamma2&#34;]
        #print(f&#34;colorthreshold.paramlist = {paramlist}&#34;)
        self.set_params(paramlist)
        #print(f&#34;_init_.self.params={self.params}&#34;)
          


    def evaluate(self, img):  # XX
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;
        minlist = [&#34;alpha1&#34;, &#34;beta1&#34;, &#34;gamma1&#34;]
        maxlist = [&#34;alpha2&#34;, &#34;beta2&#34;, &#34;gamma2&#34;]

        output = None

        #print(f&#34;self.params={self.params}&#34;)
        if (len(img.shape) &gt; 2):
            output = np.ones([img.shape[0], img.shape[1]])
            for dimidx in range(3):
                pscale = np.max(img[:, :, dimidx])
                my_mn = float(self.params[minlist[dimidx]]) * pscale
                my_mx = float(self.params[maxlist[dimidx]])  * pscale

                if my_mn &lt; my_mx:
                    output[img[:, :, dimidx] &lt; my_mn] = 0
                    output[img[:, :, dimidx] &gt; my_mx] = 0
                else:
                    flag1 = img[:, :, dimidx] &gt; my_mn
                    flag2 = img[:, :, dimidx] &lt; my_mx
                    output[np.logical_and(flag1, flag2)] = 0
        else:
            pscale = np.max(img)
            chidx = 0
            if &#34;channel&#34; in self.params:
                chidx = self.params[&#34;channel&#34;]
            my_mn = float(self.params[minlist[chidx]]) * pscale
            my_mx = float(self.params[maxlist[chidx]]) * pscale


            if my_mn &lt; my_mx:
                output = np.ones(img.shape)
                output[img &lt; my_mn] = 0
                output[img &gt; my_mx] = 0
            else:
                output = np.zeros(img.shape)
                output[img &gt; my_mn] = 1
                output[img &lt; my_mx] = 1
        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.ColorThreshold.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):  # XX
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.

    &#34;&#34;&#34;
    minlist = [&#34;alpha1&#34;, &#34;beta1&#34;, &#34;gamma1&#34;]
    maxlist = [&#34;alpha2&#34;, &#34;beta2&#34;, &#34;gamma2&#34;]

    output = None

    #print(f&#34;self.params={self.params}&#34;)
    if (len(img.shape) &gt; 2):
        output = np.ones([img.shape[0], img.shape[1]])
        for dimidx in range(3):
            pscale = np.max(img[:, :, dimidx])
            my_mn = float(self.params[minlist[dimidx]]) * pscale
            my_mx = float(self.params[maxlist[dimidx]])  * pscale

            if my_mn &lt; my_mx:
                output[img[:, :, dimidx] &lt; my_mn] = 0
                output[img[:, :, dimidx] &gt; my_mx] = 0
            else:
                flag1 = img[:, :, dimidx] &gt; my_mn
                flag2 = img[:, :, dimidx] &lt; my_mx
                output[np.logical_and(flag1, flag2)] = 0
    else:
        pscale = np.max(img)
        chidx = 0
        if &#34;channel&#34; in self.params:
            chidx = self.params[&#34;channel&#34;]
        my_mn = float(self.params[minlist[chidx]]) * pscale
        my_mx = float(self.params[maxlist[chidx]]) * pscale


        if my_mn &lt; my_mx:
            output = np.ones(img.shape)
            output[img &lt; my_mn] = 0
            output[img &gt; my_mx] = 0
        else:
            output = np.zeros(img.shape)
            output[img &gt; my_mn] = 1
            output[img &lt; my_mx] = 1
    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.Felzenszwalb"><code class="flex name class">
<span>class <span class="ident">Felzenszwalb</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform Felzenszwalb segmentation algorithm. The felzenszwalb algorithms computes a
graph based on the segmentation. Produces an oversegmentation of the multichannel using
min-span tree. Returns an integer mask indicating the segment labels.</p>
<p>Note: a colorspace of 'HSV' and a channel of 2 is a grayscale image. </p>
<p><a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.felzenszwalb">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.felzenszwalb</a></p>
<p>Parameters:
colorspace - (colorspace) Select the colorspace (0:RGB, 1:HSV, 2:LAB)
channel - (channel) color chanel (0:R/H/L 1:G/S/A, 2:B/V/B)
scale - (alpha2<em>1000) - float, higher meanse larger clusters
sigma - (alpha1) - float, std. dev of Gaussian kernel for preprocessing
min_size - int(beta1</em>100) - int, minimum component size (in pixels). For postprocessing</p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Felzenszwalb(segmentor):
    &#34;&#34;&#34;Perform Felzenszwalb segmentation algorithm. The felzenszwalb algorithms computes a 
    graph based on the segmentation. Produces an oversegmentation of the multichannel using 
    min-span tree. Returns an integer mask indicating the segment labels.

    Note: a colorspace of &#39;HSV&#39; and a channel of 2 is a grayscale image. 

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.felzenszwalb

    Parameters:
    colorspace - (colorspace) Select the colorspace (0:RGB, 1:HSV, 2:LAB)
    channel - (channel) color chanel (0:R/H/L 1:G/S/A, 2:B/V/B)
    scale - (alpha2*1000) - float, higher meanse larger clusters
    sigma - (alpha1) - float, std. dev of Gaussian kernel for preprocessing
    min_size - int(beta1*100) - int, minimum component size (in pixels). For postprocessing
    &#34;&#34;&#34;

#     def __doc__(self):
#         &#34;&#34;&#34;Return help string for function.&#34;&#34;&#34;
#         myhelp = &#34;Wrapper function for the scikit-image Felzenszwalb segmentor:&#34;
#         myhelp += f&#34; xx {skimage.segmentation.random_walker.__doc__}&#34;
#         return myhelp

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Felzenszwalb, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Felzenszwalb&#34;
        self.params[&#34;alpha2&#34;] = 0.984
        self.params[&#34;alpha1&#34;] = 0.09
        self.params[&#34;beta1&#34;] = 0.92
        self.paramindexes = [&#34;alpha1&#34;, &#34;alpha2&#34;, &#34;beta1&#34;]
        self.set_params(paramlist)
                
    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        scale = self.params[&#34;alpha2&#34;]*1000
        sigma = self.params[&#34;alpha1&#34;]
        min_size = int(self.params[&#34;beta1&#34;]*100)

        if (len(img.shape) &gt; 2):
            output = skimage.segmentation.felzenszwalb(
                img,
                scale,
                sigma,
                min_size,
                multichannel=True
            )
        else:
            output = skimage.segmentation.felzenszwalb(
                img,
                scale,
                sigma,
                min_size,
                multichannel=False
            )

        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.Felzenszwalb.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.

    &#34;&#34;&#34;

    scale = self.params[&#34;alpha2&#34;]*1000
    sigma = self.params[&#34;alpha1&#34;]
    min_size = int(self.params[&#34;beta1&#34;]*100)

    if (len(img.shape) &gt; 2):
        output = skimage.segmentation.felzenszwalb(
            img,
            scale,
            sigma,
            min_size,
            multichannel=True
        )
    else:
        output = skimage.segmentation.felzenszwalb(
            img,
            scale,
            sigma,
            min_size,
            multichannel=False
        )

    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.MorphGeodesicActiveContour"><code class="flex name class">
<span>class <span class="ident">MorphGeodesicActiveContour</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Peform Morphological Geodesic Active Contour segmentation algorithm. Uses
an image from inverse_gaussian_gradient in order to segment object with visible,
but noisy/broken borders. inverse_gaussian_gradient computes the magnitude of
the gradients in an image. Returns a preprocessed image suitable for above function.
Returns ndarray of segmented image.</p>
<p>Parameters:
gimage &ndash; array, preprocessed image to be segmented.
iterations &ndash; uint, number of iterations to run.
init_level_set &ndash; str, array same shape as gimage. If string, possible
values are:
'checkerboard': Uses checkerboard_level_set. Returns a binary level set of a checkerboard
'circle': Uses circle_level_set. Creates a binary level set of a circle, given radius and a
center
smoothing &ndash; uint, number of times the smoothing operator is applied
per iteration. Usually 1-4, larger values have smoother segmentation.
threshold &ndash; Areas of image with a smaller value than the threshold are borders.
balloon &ndash; float, guides contour of low-information parts of image.</p>
<p>morphological_geodesic_active_contour
<a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_geodesic_active_contour">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_geodesic_active_contour</a></p>
<p>Preprocessign step:
<a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.inverse_gaussian_gradient">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.inverse_gaussian_gradient</a></p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MorphGeodesicActiveContour(segmentor):
    &#34;&#34;&#34;Peform Morphological Geodesic Active Contour segmentation algorithm. Uses
     an image from inverse_gaussian_gradient in order to segment object with visible,
      but noisy/broken borders. inverse_gaussian_gradient computes the magnitude of
       the gradients in an image. Returns a preprocessed image suitable for above function.
        Returns ndarray of segmented image.

    Parameters:
    gimage -- array, preprocessed image to be segmented.
    iterations -- uint, number of iterations to run.
    init_level_set -- str, array same shape as gimage. If string, possible
        values are:
        &#39;checkerboard&#39;: Uses checkerboard_level_set. Returns a binary level set of a checkerboard
        &#39;circle&#39;: Uses circle_level_set. Creates a binary level set of a circle, given radius and a
            center
    smoothing -- uint, number of times the smoothing operator is applied
        per iteration. Usually 1-4, larger values have smoother segmentation.
    threshold -- Areas of image with a smaller value than the threshold are borders.
    balloon -- float, guides contour of low-information parts of image.

    morphological_geodesic_active_contour
    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_geodesic_active_contour

    Preprocessign step:
    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.inverse_gaussian_gradient


    &#34;&#34;&#34;

    # Abbrevieation for algorithm = AC

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(MorphGeodesicActiveContour, self).__init__(paramlist)
        if not paramlist:
            self.params[&#34;algorithm&#34;] = &#34;MorphGeodesicActiveContour&#34;
            self.params[&#34;alpha1&#34;] = 1
            self.params[&#34;alpha2&#34;] = 1
            self.params[&#34;beta1&#34;] = 0.2
            self.params[&#34;beta2&#34;] = 0.3
            self.params[&#34;beta2&#34;] = 1
            self.params[&#34;max_iter&#34;] = 10
            self.params[&#34;n_segments&#34;] = 0
            # self.params[&#34;tolerance&#34;] = 0.001 #TODO Removed, consider adding in later if need be.
        self.paramindexes = [&#34;alpha1&#34;,  &#34;alpha2&#34;,
                             &#34;beta1&#34;, &#34;beta2&#34;, &#34;n_segments&#34;, &#34;max_iter&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        # TODO We may want to move this? We need a number 1-4 smoothing iterations
        smoothing = int(self.params[&#34;alpha1&#34;]*4)
        balloon = (self.params[&#34;alpha2&#34;]*100)-50
        max_iter = self.params[&#34;max_iter&#34;]
        level_set_shapes = [&#39;checkerboard&#39;, &#39;circle&#39;]
        init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 2]

        if(len(img.shape) &gt; 2):
            if &#34;channel&#34; in self.params:
                channel = self.params[&#39;channel&#39;]
                img = img[:, :, channel]
            else:
                img = color.rgb2gray(img)

        # We run the inverse_gaussian_gradient to get the image to use
        gimage = skimage.segmentation.inverse_gaussian_gradient(
            img, self.params[&#34;beta1&#34;], self.params[&#34;beta2&#34;]
        )
        # zeros = 0
        output = skimage.segmentation.morphological_geodesic_active_contour(
            gimage,
            max_iter,
            init_level_set,
            smoothing,
            threshold=&#34;auto&#34;,
            balloon=balloon,
        )
        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.MorphGeodesicActiveContour.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.

    &#34;&#34;&#34;

    # TODO We may want to move this? We need a number 1-4 smoothing iterations
    smoothing = int(self.params[&#34;alpha1&#34;]*4)
    balloon = (self.params[&#34;alpha2&#34;]*100)-50
    max_iter = self.params[&#34;max_iter&#34;]
    level_set_shapes = [&#39;checkerboard&#39;, &#39;circle&#39;]
    init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 2]

    if(len(img.shape) &gt; 2):
        if &#34;channel&#34; in self.params:
            channel = self.params[&#39;channel&#39;]
            img = img[:, :, channel]
        else:
            img = color.rgb2gray(img)

    # We run the inverse_gaussian_gradient to get the image to use
    gimage = skimage.segmentation.inverse_gaussian_gradient(
        img, self.params[&#34;beta1&#34;], self.params[&#34;beta2&#34;]
    )
    # zeros = 0
    output = skimage.segmentation.morphological_geodesic_active_contour(
        gimage,
        max_iter,
        init_level_set,
        smoothing,
        threshold=&#34;auto&#34;,
        balloon=balloon,
    )
    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.Morphological_Chan_Vese"><code class="flex name class">
<span>class <span class="ident">Morphological_Chan_Vese</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Peform Morphological Chan Vese segmentation algorithm.
ONLY WORKS ON GRAYSCALE. Active contours without edges. Can be used to
segment images/volumes without good borders. Required that the inside of
the object looks different than outside (color, shade, darker).</p>
<p>Parameters:
image &ndash; ndarray of grayscale image
iterations &ndash; uint, number of iterations to run
init_level_set &ndash; str, or array same shape as image. Accepted string
values are:
'checkerboard': Uses checkerboard_level_set. Returns a binary level set of a checkerboard
'circle': Uses circle_level_set. Creates a binary level set of a circle, given radius and a
center
smoothing &ndash; uint, number of times the smoothing operator is applied
per iteration. Usually around 1-4. Larger values make it smoother
lambda1 &ndash; Weight param for outer region. If larger than lambda2,
outer region will give larger range of values than inner value.
lambda2 &ndash; Weight param for inner region. If larger thant lambda1,
inner region will have a larger range of values than outer region.</p>
<p><a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_chan_vese">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_chan_vese</a></p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Morphological_Chan_Vese(segmentor):
    &#34;&#34;&#34;Peform Morphological Chan Vese segmentation algorithm.
     ONLY WORKS ON GRAYSCALE. Active contours without edges. Can be used to
      segment images/volumes without good borders. Required that the inside of
       the object looks different than outside (color, shade, darker).

    Parameters:
    image -- ndarray of grayscale image
    iterations -- uint, number of iterations to run
    init_level_set -- str, or array same shape as image. Accepted string
        values are:
        &#39;checkerboard&#39;: Uses checkerboard_level_set. Returns a binary level set of a checkerboard
        &#39;circle&#39;: Uses circle_level_set. Creates a binary level set of a circle, given radius and a
            center
    smoothing -- uint, number of times the smoothing operator is applied
        per iteration. Usually around 1-4. Larger values make it smoother
    lambda1 -- Weight param for outer region. If larger than lambda2,
        outer region will give larger range of values than inner value.
    lambda2 -- Weight param for inner region. If larger thant lambda1,
        inner region will have a larger range of values than outer region.

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.morphological_chan_vese

    &#34;&#34;&#34;

    # Abbreviation for algorithm = MCV

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Morphological_Chan_Vese, self).__init__(paramlist)
        if not paramlist:
            self.params[&#34;algorithm&#34;] = &#34;Morphological_Chan_Vese&#34;
            self.params[&#34;alpha1&#34;] = 1
            self.params[&#34;beta1&#34;] = 1
            self.params[&#34;beta2&#34;] = 1
            self.params[&#34;max_iter&#34;] = 10
            self.params[&#34;n_segments&#34;] = 0
            # self.params[&#34;tolerance&#34;] = 0.001 #TODO Removed, consider adding in later if need be.
        self.paramindexes = [&#34;alpha1&#34;,  &#34;beta1&#34;,
                             &#34;beta2&#34;, &#34;n_segments&#34;, &#34;max_iter&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        # TODO We may want to move this? We need a number 1-4 smoothing iterations
        smoothing = int(self.params[&#34;alpha1&#34;]*4)

        # TODO Not sure about the range of these. Previous was (10,20)
        lambda1 = self.params[&#34;beta1&#34;]
        lambda2 = self.params[&#34;beta2&#34;]
        max_iter = self.params[&#34;max_iter&#34;]
        level_set_shapes = [&#39;checkerboard&#39;, &#39;circle&#39;]
        init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 2]

        if(len(img.shape) &gt; 2):
            if &#34;channel&#34; in self.params:
                channel = self.params[&#39;channel&#39;]
                img = img[:, :, channel]
            else:
                img = color.rgb2gray(img)

        output = skimage.segmentation.morphological_chan_vese(
            img,
            iterations=max_iter,
            init_level_set=init_level_set,
            smoothing=smoothing,
            lambda1=lambda1,
            lambda2=lambda2,
        )
        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.Morphological_Chan_Vese.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.

    &#34;&#34;&#34;

    # TODO We may want to move this? We need a number 1-4 smoothing iterations
    smoothing = int(self.params[&#34;alpha1&#34;]*4)

    # TODO Not sure about the range of these. Previous was (10,20)
    lambda1 = self.params[&#34;beta1&#34;]
    lambda2 = self.params[&#34;beta2&#34;]
    max_iter = self.params[&#34;max_iter&#34;]
    level_set_shapes = [&#39;checkerboard&#39;, &#39;circle&#39;]
    init_level_set = level_set_shapes[self.params[&#39;n_segments&#39;] % 2]

    if(len(img.shape) &gt; 2):
        if &#34;channel&#34; in self.params:
            channel = self.params[&#39;channel&#39;]
            img = img[:, :, channel]
        else:
            img = color.rgb2gray(img)

    output = skimage.segmentation.morphological_chan_vese(
        img,
        iterations=max_iter,
        init_level_set=init_level_set,
        smoothing=smoothing,
        lambda1=lambda1,
        lambda2=lambda2,
    )
    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.QuickShift"><code class="flex name class">
<span>class <span class="ident">QuickShift</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the Quick Shift segmentation algorithm. Segments images with quickshift
clustering in Color (x,y) space. Returns ndarray segmentation mask of the labels.</p>
<p>Parameters:
image &ndash; ndarray, input image
ratio &ndash; float, balances color-space proximity &amp; image-space
proximity. Higher vals give more weight to color-space
kernel_size: float, Width of Guassian kernel using smoothing.
Higher means fewer clusters
max_dist &ndash; float, Cut-off point for data distances. Higher means fewer clusters
sigma &ndash; float, Width of Guassian smoothing as preprocessing.
Zero means no smoothing
random_seed &ndash; int, Random seed used for breacking ties.</p>
<p><a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.quickshift">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.quickshift</a></p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class QuickShift(segmentor):
    &#34;&#34;&#34;Perform the Quick Shift segmentation algorithm. Segments images with quickshift
     clustering in Color (x,y) space. Returns ndarray segmentation mask of the labels.

    Parameters:
    image -- ndarray, input image
    ratio -- float, balances color-space proximity &amp; image-space
        proximity. Higher vals give more weight to color-space
    kernel_size: float, Width of Guassian kernel using smoothing.
        Higher means fewer clusters
    max_dist -- float, Cut-off point for data distances. Higher means fewer clusters
    sigma -- float, Width of Guassian smoothing as preprocessing.
        Zero means no smoothing
    random_seed -- int, Random seed used for breacking ties.

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.quickshift

    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(QuickShift, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;QuickShift&#34;
        self.params[&#34;alpha1&#34;] = 0.5
        self.params[&#34;beta1&#34;] = 0.5
        self.params[&#34;beta2&#34;] = 0.5
        self.paramindexes = [&#34;alpha1&#34;, &#34;beta1&#34;, &#34;beta2&#34;]
        self.set_params(paramlist)

    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        mindim = min(img.shape)
        ratio = self.params[&#34;alpha1&#34;]
        kernel_size = mindim/10*self.params[&#34;beta1&#34;]+1
        max_dist = mindim*self.params[&#34;beta2&#34;]
        output = skimage.segmentation.quickshift(
            img,
            ratio=ratio,
            kernel_size=kernel_size,
            max_dist=max_dist,
            sigma=0,  # TODO this should be handeled in the preprocessing step
            random_seed=1,
            convert2lab=False
        )
        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.QuickShift.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.

    &#34;&#34;&#34;

    mindim = min(img.shape)
    ratio = self.params[&#34;alpha1&#34;]
    kernel_size = mindim/10*self.params[&#34;beta1&#34;]+1
    max_dist = mindim*self.params[&#34;beta2&#34;]
    output = skimage.segmentation.quickshift(
        img,
        ratio=ratio,
        kernel_size=kernel_size,
        max_dist=max_dist,
        sigma=0,  # TODO this should be handeled in the preprocessing step
        random_seed=1,
        convert2lab=False
    )
    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.Slic"><code class="flex name class">
<span>class <span class="ident">Slic</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the Slic segmentation algorithm. Segments k-means clustering in Color space
(x, y, z). Returns a 2D or 3D array of labels.</p>
<p>Parameters:
image &ndash; ndarray, input image
n_segments &ndash; int, approximate number of labels in segmented output image
compactness &ndash; float, Balances color proximity and space proximity.
Higher values mean more weight to space proximity (superpixels
become more square/cubic) Recommended log scale values (0.01,
0.1, 1, 10, 100, etc)
max_iter &ndash; int, max number of iterations of k-means
sigma &ndash; float or (3,) shape array of floats, width of Guassian
smoothing kernel. For pre-processing for each dimesion of the
image. Zero means no smoothing.
spacing &ndash; (3,) shape float array. Voxel spacing along each image
dimension. Defalt is uniform spacing
multichannel &ndash; bool,
multichannel (True) vs grayscale (False)</p>
<p>enforce_connectivity</p>
<p><a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic</a></p>
<p><a href="https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/">https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/</a></p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Slic(segmentor):
    &#34;&#34;&#34;Perform the Slic segmentation algorithm. Segments k-means clustering in Color space
     (x, y, z). Returns a 2D or 3D array of labels.

    Parameters:
    image -- ndarray, input image
    n_segments -- int, approximate number of labels in segmented output image
    compactness -- float, Balances color proximity and space proximity.
        Higher values mean more weight to space proximity (superpixels
        become more square/cubic) Recommended log scale values (0.01,
        0.1, 1, 10, 100, etc)
    max_iter -- int, max number of iterations of k-means
    sigma -- float or (3,) shape array of floats, width of Guassian
        smoothing kernel. For pre-processing for each dimesion of the
        image. Zero means no smoothing.
    spacing -- (3,) shape float array. Voxel spacing along each image
        dimension. Defalt is uniform spacing
    multichannel -- bool,  multichannel (True) vs grayscale (False)

    enforce_connectivity

   https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic

   https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/


    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Slic, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Slic&#34;
        self.params[&#34;n_segments&#34;] = 5
        self.params[&#34;beta1&#34;] = 2
        self.params[&#34;max_iter&#34;] = 10
        self.params[&#34;alpha1&#34;] = 0.5
        self.paramindexes = [&#34;n_segments&#34;, &#34;alpha1&#34;, &#34;beta1&#34;, &#34;max_iter&#34;]
        self.slico = False
        self.set_params(paramlist)
                
    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.

        &#34;&#34;&#34;

        compactness = 10**(self.params[&#34;beta1&#34;]*3-3)
        n_segments = self.params[&#34;n_segments&#34;]+1
        max_iter = self.params[&#34;max_iter&#34;]
        if (len(img.shape) &gt; 2):
            output = skimage.segmentation.slic(
                img,
                n_segments=n_segments,
                compactness=compactness,
                max_iter=max_iter,
                # Gaussian smoothing should happen as a preprocessing step.
                sigma=0,
                convert2lab=False,
                multichannel=True,
                slic_zero=self.slico
            )
        else:
            output = skimage.segmentation.slic(
                img,
                n_segments=n_segments,
                compactness=compactness,
                max_iter=max_iter,
                sigma=self.params[&#34;alpha1&#34;],
                multichannel=False,
                slic_zero=self.slico
            )
        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="see.Segmentors.SlicO" href="#see.Segmentors.SlicO">SlicO</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.Slic.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.

    &#34;&#34;&#34;

    compactness = 10**(self.params[&#34;beta1&#34;]*3-3)
    n_segments = self.params[&#34;n_segments&#34;]+1
    max_iter = self.params[&#34;max_iter&#34;]
    if (len(img.shape) &gt; 2):
        output = skimage.segmentation.slic(
            img,
            n_segments=n_segments,
            compactness=compactness,
            max_iter=max_iter,
            # Gaussian smoothing should happen as a preprocessing step.
            sigma=0,
            convert2lab=False,
            multichannel=True,
            slic_zero=self.slico
        )
    else:
        output = skimage.segmentation.slic(
            img,
            n_segments=n_segments,
            compactness=compactness,
            max_iter=max_iter,
            sigma=self.params[&#34;alpha1&#34;],
            multichannel=False,
            slic_zero=self.slico
        )
    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.SlicO"><code class="flex name class">
<span>class <span class="ident">SlicO</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the SlicO segmentation algorithm. Segments k-means clustering in Color space
(x, y, z). Returns a 2D or 3D array of labels.</p>
<p>Parameters:
image &ndash; ndarray, input image
n_segments &ndash; int, approximate number of labels in segmented output image
compactness &ndash; float, Balances color proximity and space proximity.
Higher values mean more weight to space proximity (superpixels
become more square/cubic) Recommended log scale values (0.01,
0.1, 1, 10, 100, etc)
max_iter &ndash; int, max number of iterations of k-means
sigma &ndash; float or (3,) shape array of floats, width of Guassian
smoothing kernel. For pre-processing for each dimesion of the
image. Zero means no smoothing.
spacing &ndash; (3,) shape float array. Voxel spacing along each image
dimension. Defalt is uniform spacing
multichannel &ndash; bool,
multichannel (True) vs grayscale (False)</p>
<p>enforce_connectivity</p>
<p><a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic</a></p>
<p><a href="https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/">https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/</a></p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SlicO(Slic):
    &#34;&#34;&#34;Perform the SlicO segmentation algorithm. Segments k-means clustering in Color space
     (x, y, z). Returns a 2D or 3D array of labels.

    Parameters:
    image -- ndarray, input image
    n_segments -- int, approximate number of labels in segmented output image
    compactness -- float, Balances color proximity and space proximity.
        Higher values mean more weight to space proximity (superpixels
        become more square/cubic) Recommended log scale values (0.01,
        0.1, 1, 10, 100, etc)
    max_iter -- int, max number of iterations of k-means
    sigma -- float or (3,) shape array of floats, width of Guassian
        smoothing kernel. For pre-processing for each dimesion of the
        image. Zero means no smoothing.
    spacing -- (3,) shape float array. Voxel spacing along each image
        dimension. Defalt is uniform spacing
    multichannel -- bool,  multichannel (True) vs grayscale (False)

    enforce_connectivity

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic

    https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/


    &#34;&#34;&#34;

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(SlicO, self).__init__(paramlist)
        self.slico = True
        self.set_params(paramlist)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.Slic" href="#see.Segmentors.Slic">Slic</a></li>
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.Slic" href="#see.Segmentors.Slic">Slic</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.Slic.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.Slic.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.Slic.evaluate" href="#see.Segmentors.Slic.evaluate">evaluate</a></code></li>
<li><code><a title="see.Segmentors.Slic.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.Slic.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.Slic.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.Watershed"><code class="flex name class">
<span>class <span class="ident">Watershed</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the Watershed segmentation algorithm. Uses user-markers.
treats markers as basins and 'floods' them. Especially good if overlapping objects.
Returns a labeled image ndarray.</p>
<p>Parameters:
image &ndash; ndarray, input array
compactness &ndash; float, compactness of the basins. Higher values
make more regularly-shaped basin.</p>
<p><a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.watershed">https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.watershed</a></p>
<p>Get parameters from parameter list that are used in segmentation algorithm.
Assign default values to these parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Watershed(segmentor):
    &#34;&#34;&#34;Perform the Watershed segmentation algorithm. Uses user-markers.
     treats markers as basins and &#39;floods&#39; them. Especially good if overlapping objects.
      Returns a labeled image ndarray.

    Parameters:
    image -- ndarray, input array
    compactness -- float, compactness of the basins. Higher values
        make more regularly-shaped basin.

    https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.watershed

    &#34;&#34;&#34;

    # Not using connectivity, markers, or offset params as arrays would
    # expand the search space too much.
    # abbreviation for algorithm = WS

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Get parameters from parameter list that are used in segmentation algorithm.
         Assign default values to these parameters.&#34;&#34;&#34;
        super(Watershed, self).__init__(paramlist)
        self.params[&#34;algorithm&#34;] = &#34;Watershed&#34;
        self.params[&#34;alpha1&#34;] = 0.66
        self.paramindexes = [&#34;alpha1&#34;]
        self.set_params(paramlist)
                
    def evaluate(self, img):
        &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

        Keyword arguments:
        img -- Original training image.

        Output:
        output -- resulting segmentation mask from algorithm.



        &#34;&#34;&#34;

        compactness = self.params[&#34;alpha1&#34;]*3

        output = skimage.segmentation.watershed(
            img, markers=None, compactness=compactness
        )
        return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></li>
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.Watershed.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate segmentation algorithm on training image.</p>
<p>Keyword arguments:
img &ndash; Original training image.</p>
<p>Output:
output &ndash; resulting segmentation mask from algorithm.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Evaluate segmentation algorithm on training image.

    Keyword arguments:
    img -- Original training image.

    Output:
    output -- resulting segmentation mask from algorithm.



    &#34;&#34;&#34;

    compactness = self.params[&#34;alpha1&#34;]*3

    output = skimage.segmentation.watershed(
        img, markers=None, compactness=compactness
    )
    return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></b></code>:
<ul class="hlist">
<li><code><a title="see.Segmentors.segmentor.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.Segmentors.segmentor.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.Segmentors.segmentor.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.Segmentors.segmentor.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.Segmentors.segmentor.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.seg_params"><code class="flex name class">
<span>class <span class="ident">seg_params</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Construct an parameter dictionary that represents the search space.</p>
<h2 id="components">Components</h2>
<p>pkeys - paramters keys used by the current algorithsm.
descriptions - Descriptions of the parameters
ranges - List of possible choices for each parameter.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class seg_params(param_space):
    descriptions = dict()
    ranges = dict()
    pkeys = []</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.base_classes.param_space" href="base_classes.html#see.base_classes.param_space">param_space</a></li>
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="see.Segmentors.seg_params.descriptions"><code class="name">var <span class="ident">descriptions</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="see.Segmentors.seg_params.pkeys"><code class="name">var <span class="ident">pkeys</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="see.Segmentors.seg_params.ranges"><code class="name">var <span class="ident">ranges</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.base_classes.param_space" href="base_classes.html#see.base_classes.param_space">param_space</a></b></code>:
<ul class="hlist">
<li><code><a title="see.base_classes.param_space.add" href="base_classes.html#see.base_classes.param_space.add">add</a></code></li>
<li><code><a title="see.base_classes.param_space.addall" href="base_classes.html#see.base_classes.param_space.addall">addall</a></code></li>
<li><code><a title="see.base_classes.param_space.fromlist" href="base_classes.html#see.base_classes.param_space.fromlist">fromlist</a></code></li>
<li><code><a title="see.base_classes.param_space.printparam" href="base_classes.html#see.base_classes.param_space.printparam">printparam</a></code></li>
<li><code><a title="see.base_classes.param_space.tolist" href="base_classes.html#see.base_classes.param_space.tolist">tolist</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="see.Segmentors.segmentor"><code class="flex name class">
<span>class <span class="ident">segmentor</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for segmentor classes defined below.</p>
<p>Functions:
evaluate &ndash; Run segmentation algorithm to get inferred mask.</p>
<p>Generate algorithm params from parameter list.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class segmentor(algorithm):
    &#34;&#34;&#34;Base class for segmentor classes defined below.

    Functions:
    evaluate -- Run segmentation algorithm to get inferred mask.

    &#34;&#34;&#34;

    algorithmspace = dict()

    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Generate algorithm params from parameter list.&#34;&#34;&#34;
        #super(ColorThreshold, self).__init__(paramlist)
        self.params = seg_params()

        self.params[&#39;algorithm&#39;] = &#39;ColorThreshold&#39;
        self.params[&#39;alpha1&#39;] = 0.3
        self.params[&#39;alpha2&#39;] = 0.5
        self.params[&#39;beta1&#39;] = 0.2
        self.params[&#39;beta2&#39;] = 0.7
        self.params[&#39;gamma1&#39;] = 0.3
        self.params[&#39;gamma2&#39;] = 0.5
        self.params[&#39;n_segments&#39;] = 2
        self.params[&#39;max_iter&#39;] = 10
        self.set_params(paramlist)

        
    # TODO use name to build a dictionary to use as a chache
    def evaluate(self, img):
        &#34;&#34;&#34;Run segmentation algorithm to get inferred mask.&#34;&#34;&#34;
        import sys

        #print(f&#34;Running {self.params}&#34;)
        sys.stdout.flush()
        self.thisalgo = segmentor.algorithmspace[self.params[&#39;algorithm&#39;]](self.params)
        return self.thisalgo.evaluate(img)

    def pipe(self, data):
        data.mask = self.evaluate(data.img)
        return data

    @classmethod
    def addsegmentor(cls, key, seg):
        seg_params.ranges[&#39;algorithm&#39;].append(key)
        cls.algorithmspace[key] = seg</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="see.Segmentors.Chan_Vese" href="#see.Segmentors.Chan_Vese">Chan_Vese</a></li>
<li><a title="see.Segmentors.ColorThreshold" href="#see.Segmentors.ColorThreshold">ColorThreshold</a></li>
<li><a title="see.Segmentors.Felzenszwalb" href="#see.Segmentors.Felzenszwalb">Felzenszwalb</a></li>
<li><a title="see.Segmentors.MorphGeodesicActiveContour" href="#see.Segmentors.MorphGeodesicActiveContour">MorphGeodesicActiveContour</a></li>
<li><a title="see.Segmentors.Morphological_Chan_Vese" href="#see.Segmentors.Morphological_Chan_Vese">Morphological_Chan_Vese</a></li>
<li><a title="see.Segmentors.QuickShift" href="#see.Segmentors.QuickShift">QuickShift</a></li>
<li><a title="see.Segmentors.Slic" href="#see.Segmentors.Slic">Slic</a></li>
<li><a title="see.Segmentors.Watershed" href="#see.Segmentors.Watershed">Watershed</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="see.Segmentors.segmentor.algorithmspace"><code class="name">var <span class="ident">algorithmspace</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="see.Segmentors.segmentor.addsegmentor"><code class="name flex">
<span>def <span class="ident">addsegmentor</span></span>(<span>key, seg)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def addsegmentor(cls, key, seg):
    seg_params.ranges[&#39;algorithm&#39;].append(key)
    cls.algorithmspace[key] = seg</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="see.Segmentors.segmentor.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"><p>Run segmentation algorithm to get inferred mask.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, img):
    &#34;&#34;&#34;Run segmentation algorithm to get inferred mask.&#34;&#34;&#34;
    import sys

    #print(f&#34;Running {self.params}&#34;)
    sys.stdout.flush()
    self.thisalgo = segmentor.algorithmspace[self.params[&#39;algorithm&#39;]](self.params)
    return self.thisalgo.evaluate(img)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></b></code>:
<ul class="hlist">
<li><code><a title="see.base_classes.algorithm.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.base_classes.algorithm.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.base_classes.algorithm.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.base_classes.algorithm.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.base_classes.algorithm.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="see" href="index.html">see</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="see.Segmentors.Chan_Vese" href="#see.Segmentors.Chan_Vese">Chan_Vese</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.Chan_Vese.evaluate" href="#see.Segmentors.Chan_Vese.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.ColorThreshold" href="#see.Segmentors.ColorThreshold">ColorThreshold</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.ColorThreshold.evaluate" href="#see.Segmentors.ColorThreshold.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.Felzenszwalb" href="#see.Segmentors.Felzenszwalb">Felzenszwalb</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.Felzenszwalb.evaluate" href="#see.Segmentors.Felzenszwalb.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.MorphGeodesicActiveContour" href="#see.Segmentors.MorphGeodesicActiveContour">MorphGeodesicActiveContour</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.MorphGeodesicActiveContour.evaluate" href="#see.Segmentors.MorphGeodesicActiveContour.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.Morphological_Chan_Vese" href="#see.Segmentors.Morphological_Chan_Vese">Morphological_Chan_Vese</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.Morphological_Chan_Vese.evaluate" href="#see.Segmentors.Morphological_Chan_Vese.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.QuickShift" href="#see.Segmentors.QuickShift">QuickShift</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.QuickShift.evaluate" href="#see.Segmentors.QuickShift.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.Slic" href="#see.Segmentors.Slic">Slic</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.Slic.evaluate" href="#see.Segmentors.Slic.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.SlicO" href="#see.Segmentors.SlicO">SlicO</a></code></h4>
</li>
<li>
<h4><code><a title="see.Segmentors.Watershed" href="#see.Segmentors.Watershed">Watershed</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.Watershed.evaluate" href="#see.Segmentors.Watershed.evaluate">evaluate</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.seg_params" href="#see.Segmentors.seg_params">seg_params</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.seg_params.descriptions" href="#see.Segmentors.seg_params.descriptions">descriptions</a></code></li>
<li><code><a title="see.Segmentors.seg_params.pkeys" href="#see.Segmentors.seg_params.pkeys">pkeys</a></code></li>
<li><code><a title="see.Segmentors.seg_params.ranges" href="#see.Segmentors.seg_params.ranges">ranges</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="see.Segmentors.segmentor" href="#see.Segmentors.segmentor">segmentor</a></code></h4>
<ul class="">
<li><code><a title="see.Segmentors.segmentor.addsegmentor" href="#see.Segmentors.segmentor.addsegmentor">addsegmentor</a></code></li>
<li><code><a title="see.Segmentors.segmentor.algorithmspace" href="#see.Segmentors.segmentor.algorithmspace">algorithmspace</a></code></li>
<li><code><a title="see.Segmentors.segmentor.evaluate" href="#see.Segmentors.segmentor.evaluate">evaluate</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>