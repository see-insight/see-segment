<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>see.Segment_Similarity_Measure API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>see.Segment_Similarity_Measure</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import sys
from skimage import color
import numpy as np

def countMatches(inferred, ground_truth):
    &#34;&#34;&#34;Map the segments in the inferred segmentation mask to the ground truth segmentation
     mask, and record the number of pixels in each of these mappings as well as the number
      of segments in both masks.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.
    len(m) -- Number of segments in inferred segmentation mask.
    len(n) -- Number of segments in ground truth segmentation mask.

    &#34;&#34;&#34;
    assert inferred.shape == ground_truth.shape
    m = set()
    n = set()
    setcounts = dict()
    for r in range(inferred.shape[0]):
        for c in range(inferred.shape[1]):
            i_key = inferred[r, c]
            m.add(i_key)
            g_key = ground_truth[r, c]
            n.add(g_key)
            if i_key in setcounts:
                if g_key in setcounts[i_key]:
                    setcounts[i_key][g_key] += 1
                else:
                    setcounts[i_key][g_key] = 1
            else:
                setcounts[i_key] = dict()
                setcounts[i_key][g_key] = 1
    return setcounts, len(m), len(n)

def countsets(setcounts):
    &#34;&#34;&#34;For each inferred set, find the ground truth set which it maps the most pixels
     to. So we start from the inferred image, and map towards the ground truth image.
      For each i_key, the g_key that it maps the most pixels to is considered True.
       In order to see what ground truth sets have a corresponding set(s) in the inferred
        image, we record these &#34;true&#34; g_keys. This number of true g_keys is the value for
         L in our fitness function.

    Keyword arguments:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.

    Outputs:
    (total - p) -- Pixel error.
    L -- Number of ground truth segments that have a mapping in the inferred mask
    best -- True mapping as dictionary.

    &#34;&#34;&#34;
    p = 0
    #L = len(setcounts)

    total = 0
    L_sets = set()

    best = dict()

    for i_key in setcounts:
        my_mx = 0
        mx_key = &#39;&#39;
        for g_key in setcounts[i_key]:
            total += setcounts[i_key][g_key] # add to total pixel count
            if setcounts[i_key][g_key] &gt; my_mx:
                my_mx = setcounts[i_key][g_key]
                # mx_key = i_key
                mx_key = g_key # record mapping with greatest pixel count
        p += my_mx
        # L_sets.add(g_key)
        L_sets.add(mx_key) # add the g_key we consider to be correct
        # best[i_key] = g_key
        best[i_key] = mx_key # record &#34;true&#34; mapping
    L = len(L_sets)
    return total-p, L, best



def FF_Option1(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    error = L*(p + 2)
    
    return [error, ]


def FF_Option2a(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)) 
    
    return [error, ]


def FF_Option2b(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)+1) 
    
    return [error, ]


def FitnessFunction_old(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        print(
            f&#34;WARNING: Fitness bounds exceeded, using Maxsize - {L} &lt; {n} or {error} &lt;= 0 or {error} == np.inf or {error} == np.nan:&#34;
        )
        error = sys.maxsize
        # print(error)
    return [error, ]


def FF_Normal(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

        
    tot_num_pixels = ground_truth.shape[0] * ground_truth.shape[1] 
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    #Normalize:
    p = p/tot_num_pixels
    m = m/tot_num_pixels
    n = n/tot_num_pixels

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        error = sys.maxsize
        # print(error)
    return [error, ]

def FF_ML2DHD(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    tot_num_pixels = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    error = (p+np.abs(n-m))/(N*M)
            
            
    return [ error, n,m]
def FF_Hamming(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming +=  ground_truth[r,c] != inferred[r,c]
            
    return [hamming/(M*N), ]
def FF_Gamma(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    inferred = inferred &gt; 0
    ground_truth = ground_truth &gt; 0
    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    f = lambda u,v: u+v-(2*u*v)
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming += ground_truth[r,c] != inferred[r,c]
    
    gamma = np.abs(1-(2*hamming/(M*N)))
               
    return [1- gamma, ]

def FF_ML2DHD(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    error = p/TP+np.abs(n-m)/TP
            
            
    return [ error, n,m]

def FF_ML2DHD_V2(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, best = countsets(setcounts)
    
    test = set()
    for key in best:
        test.add(best[key])
        
    if len(test) == 1:
        #Trivial Solution
        #print(f&#34;trivial solution&#34;)
        error = 1;
    else:
        error = (p/TP+np.abs(n-m)/(n+m))**(1-np.abs(n-m)/(n+m))
        
    return [ error, n,m]


def FitnessFunction(inferred, ground_truth):
    return FF_ML2DHD_V2(inferred, ground_truth)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="see.Segment_Similarity_Measure.FF_Gamma"><code class="name flex">
<span>def <span class="ident">FF_Gamma</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Gamma(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    inferred = inferred &gt; 0
    ground_truth = ground_truth &gt; 0
    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    f = lambda u,v: u+v-(2*u*v)
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming += ground_truth[r,c] != inferred[r,c]
    
    gamma = np.abs(1-(2*hamming/(M*N)))
               
    return [1- gamma, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FF_Hamming"><code class="name flex">
<span>def <span class="ident">FF_Hamming</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Hamming(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming +=  ground_truth[r,c] != inferred[r,c]
            
    return [hamming/(M*N), ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FF_ML2DHD"><code class="name flex">
<span>def <span class="ident">FF_ML2DHD</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_ML2DHD(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    error = p/TP+np.abs(n-m)/TP
            
            
    return [ error, n,m]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FF_ML2DHD_V2"><code class="name flex">
<span>def <span class="ident">FF_ML2DHD_V2</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_ML2DHD_V2(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, best = countsets(setcounts)
    
    test = set()
    for key in best:
        test.add(best[key])
        
    if len(test) == 1:
        #Trivial Solution
        #print(f&#34;trivial solution&#34;)
        error = 1;
    else:
        error = (p/TP+np.abs(n-m)/(n+m))**(1-np.abs(n-m)/(n+m))
        
    return [ error, n,m]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FF_Normal"><code class="name flex">
<span>def <span class="ident">FF_Normal</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Normal(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

        
    tot_num_pixels = ground_truth.shape[0] * ground_truth.shape[1] 
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    #Normalize:
    p = p/tot_num_pixels
    m = m/tot_num_pixels
    n = n/tot_num_pixels

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        error = sys.maxsize
        # print(error)
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FF_Option1"><code class="name flex">
<span>def <span class="ident">FF_Option1</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Option1(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    error = L*(p + 2)
    
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FF_Option2a"><code class="name flex">
<span>def <span class="ident">FF_Option2a</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Option2a(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)) 
    
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FF_Option2b"><code class="name flex">
<span>def <span class="ident">FF_Option2b</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Option2b(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)+1) 
    
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FitnessFunction"><code class="name flex">
<span>def <span class="ident">FitnessFunction</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FitnessFunction(inferred, ground_truth):
    return FF_ML2DHD_V2(inferred, ground_truth)</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.FitnessFunction_old"><code class="name flex">
<span>def <span class="ident">FitnessFunction_old</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual. Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FitnessFunction_old(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual. Takes in two images and compares
     them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
      error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        print(
            f&#34;WARNING: Fitness bounds exceeded, using Maxsize - {L} &lt; {n} or {error} &lt;= 0 or {error} == np.inf or {error} == np.nan:&#34;
        )
        error = sys.maxsize
        # print(error)
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.countMatches"><code class="name flex">
<span>def <span class="ident">countMatches</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Map the segments in the inferred segmentation mask to the ground truth segmentation
mask, and record the number of pixels in each of these mappings as well as the number
of segments in both masks.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
setcounts &ndash; Dictionary of dictionaries containing the number of pixels in
each segment mapping.
len(m) &ndash; Number of segments in inferred segmentation mask.
len(n) &ndash; Number of segments in ground truth segmentation mask.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def countMatches(inferred, ground_truth):
    &#34;&#34;&#34;Map the segments in the inferred segmentation mask to the ground truth segmentation
     mask, and record the number of pixels in each of these mappings as well as the number
      of segments in both masks.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.
    len(m) -- Number of segments in inferred segmentation mask.
    len(n) -- Number of segments in ground truth segmentation mask.

    &#34;&#34;&#34;
    assert inferred.shape == ground_truth.shape
    m = set()
    n = set()
    setcounts = dict()
    for r in range(inferred.shape[0]):
        for c in range(inferred.shape[1]):
            i_key = inferred[r, c]
            m.add(i_key)
            g_key = ground_truth[r, c]
            n.add(g_key)
            if i_key in setcounts:
                if g_key in setcounts[i_key]:
                    setcounts[i_key][g_key] += 1
                else:
                    setcounts[i_key][g_key] = 1
            else:
                setcounts[i_key] = dict()
                setcounts[i_key][g_key] = 1
    return setcounts, len(m), len(n)</code></pre>
</details>
</dd>
<dt id="see.Segment_Similarity_Measure.countsets"><code class="name flex">
<span>def <span class="ident">countsets</span></span>(<span>setcounts)</span>
</code></dt>
<dd>
<div class="desc"><p>For each inferred set, find the ground truth set which it maps the most pixels
to. So we start from the inferred image, and map towards the ground truth image.
For each i_key, the g_key that it maps the most pixels to is considered True.
In order to see what ground truth sets have a corresponding set(s) in the inferred
image, we record these "true" g_keys. This number of true g_keys is the value for
L in our fitness function.</p>
<p>Keyword arguments:
setcounts &ndash; Dictionary of dictionaries containing the number of pixels in
each segment mapping.</p>
<p>Outputs:
(total - p) &ndash; Pixel error.
L &ndash; Number of ground truth segments that have a mapping in the inferred mask
best &ndash; True mapping as dictionary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def countsets(setcounts):
    &#34;&#34;&#34;For each inferred set, find the ground truth set which it maps the most pixels
     to. So we start from the inferred image, and map towards the ground truth image.
      For each i_key, the g_key that it maps the most pixels to is considered True.
       In order to see what ground truth sets have a corresponding set(s) in the inferred
        image, we record these &#34;true&#34; g_keys. This number of true g_keys is the value for
         L in our fitness function.

    Keyword arguments:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.

    Outputs:
    (total - p) -- Pixel error.
    L -- Number of ground truth segments that have a mapping in the inferred mask
    best -- True mapping as dictionary.

    &#34;&#34;&#34;
    p = 0
    #L = len(setcounts)

    total = 0
    L_sets = set()

    best = dict()

    for i_key in setcounts:
        my_mx = 0
        mx_key = &#39;&#39;
        for g_key in setcounts[i_key]:
            total += setcounts[i_key][g_key] # add to total pixel count
            if setcounts[i_key][g_key] &gt; my_mx:
                my_mx = setcounts[i_key][g_key]
                # mx_key = i_key
                mx_key = g_key # record mapping with greatest pixel count
        p += my_mx
        # L_sets.add(g_key)
        L_sets.add(mx_key) # add the g_key we consider to be correct
        # best[i_key] = g_key
        best[i_key] = mx_key # record &#34;true&#34; mapping
    L = len(L_sets)
    return total-p, L, best</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="see" href="index.html">see</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="see.Segment_Similarity_Measure.FF_Gamma" href="#see.Segment_Similarity_Measure.FF_Gamma">FF_Gamma</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FF_Hamming" href="#see.Segment_Similarity_Measure.FF_Hamming">FF_Hamming</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FF_ML2DHD" href="#see.Segment_Similarity_Measure.FF_ML2DHD">FF_ML2DHD</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FF_ML2DHD_V2" href="#see.Segment_Similarity_Measure.FF_ML2DHD_V2">FF_ML2DHD_V2</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FF_Normal" href="#see.Segment_Similarity_Measure.FF_Normal">FF_Normal</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FF_Option1" href="#see.Segment_Similarity_Measure.FF_Option1">FF_Option1</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FF_Option2a" href="#see.Segment_Similarity_Measure.FF_Option2a">FF_Option2a</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FF_Option2b" href="#see.Segment_Similarity_Measure.FF_Option2b">FF_Option2b</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FitnessFunction" href="#see.Segment_Similarity_Measure.FitnessFunction">FitnessFunction</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.FitnessFunction_old" href="#see.Segment_Similarity_Measure.FitnessFunction_old">FitnessFunction_old</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.countMatches" href="#see.Segment_Similarity_Measure.countMatches">countMatches</a></code></li>
<li><code><a title="see.Segment_Similarity_Measure.countsets" href="#see.Segment_Similarity_Measure.countsets">countsets</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>