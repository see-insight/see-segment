<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>see.GeneticSearch API documentation</title>
<meta name="description" content="Using the specified search space and fitness function defined in &#39;Algorithm&#39; this runs
the genetic algorithm over that space. Best individuals are â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>see.GeneticSearch</code></h1>
</header>
<section id="section-intro">
<p>Using the specified search space and fitness function defined in 'Algorithm' this runs
the genetic algorithm over that space. Best individuals are stored in the hall of fame (hof).</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Using the specified search space and fitness function defined in &#39;Algorithm&#39; this runs
 the genetic algorithm over that space. Best individuals are stored in the hall of fame (hof).&#34;&#34;&#34;

import random
import copy

import json
import logging
from shutil import copyfile

import deap
from deap import base
from deap import tools
from deap import creator
from scoop import futures

from see import base_classes


# TODO Change algoirthm and algo_instance to be more clear.  use consistant naming.


def twoPointCopy(np1, np2, seed=False):
    &#34;&#34;&#34;Execute a crossover between two numpy arrays of the same length.&#34;&#34;&#34;
    if seed == True:
        random.seed(0)
    assert len(np1) == len(np2)
    size = len(np1)
    point1 = random.randint(1, size)
    point2 = random.randint(1, size - 1)
    if point2 &gt;= point1:
        point2 += 1
    else:  # Swap the two points
        point1, point2 = point2, point1
    np1[point1:point2], np2[point1:point2] = np2[point1:point2].copy(
    ), np1[point1:point2].copy()
    return np1, np2


def skimageCrossRandom(np1, np2, seed=False):
    &#34;&#34;&#34;Execute a crossover between two arrays (np1 and np2) picking a random
     amount of indexes to change between the two.&#34;&#34;&#34;
    if seed == True:
        random.seed(0)
    # DO: Only change values associated with algorithm
    assert len(np1) == len(np2)
    # The number of places that we&#39;ll cross
    crosses = random.randrange(len(np1))
    # We pick that many crossing points
    indexes = random.sample(range(0, len(np1)), crosses)
    # And at those crossing points, we switch the parameters

    for i in indexes:
        np1[i], np2[i] = np2[i], np1[i]

    return np1, np2


def mutate(copy_child, pos_vals, flip_prob=0.5, seed=False):
    &#34;&#34;&#34;Change a few of the parameters of the weighting a random number against the flip_prob.

    Keyword arguments:
    copy_child -- the individual to mutate.
    pos_vals -- list of lists where each list are the possible
                values for that particular parameter.
    flip_prob -- how likely it is that we will mutate each value.
                It is computed seperately for each value.

    Outputs:
    child -- New, possibly mutated, individual.

    &#34;&#34;&#34;
    # Just because we chose to mutate a value doesn&#39;t mean we mutate
    # Every aspect of the value
    child = copy.deepcopy(copy_child)

    # Not every algorithm is associated with every value
    # Let&#39;s first see if we change the algorithm
    rand_val = random.random()
    if rand_val &lt; flip_prob:
        # Let&#39;s mutate
        child[0] = random.choice(pos_vals[0])
    # Now let&#39;s get the indexes (parameters) related to that value
    #switcher = AlgoHelp().algoIndexes()
    #indexes = switcher.get(child[0])

    for index in range(len(pos_vals)):
        rand_val = random.random()
        if rand_val &lt; flip_prob:
            #             # Then we mutate said value
            #             if index == 22:
            #                 # Do some special
            #                 my_x = random.choice(pos_vals[22])
            #                 my_y = random.choice(pos_vals[23])
            #                 my_z = random.choice(pos_vals[24])
            #                 child[index] = (my_x, my_y, my_z)
            #                 continue
            child[index] = random.choice(pos_vals[index])
    return child


# DO: Make a toolbox from a list of individuals
# DO: Save a population as a list of indivudals (with fitness functions?)

# TODO: change algo_instance to an algorithm class.
def makeToolbox(pop_size, algo_constructor):
    &#34;&#34;&#34;Make a genetic algorithm toolbox using DEAP. The toolbox uses premade functions
     for crossover, mutation, evaluation and fitness.

    Keyword arguments:
    pop_size -- The size of our population, or how many individuals we have

    &#34;&#34;&#34;
    # Minimizing fitness function
    creator.create(&#34;FitnessMin&#34;, base.Fitness, weights=(-0.000001,))
    creator.create(&#34;Individual&#34;, list, fitness=creator.FitnessMin)

    # The functions that the GA knows
    toolbox = base.Toolbox()

    # Genetic functions
    toolbox.register(&#34;mate&#34;, skimageCrossRandom)  # crossover
    # toolbox.register(&#34;mutate&#34;, mutate)  # Mutation
    toolbox.register(&#34;mutate&#34;, base_classes.mutateAlgo)  # Mutation
    toolbox.register(&#34;evaluate&#34;, algo_constructor.runAlgo)  # Fitness
    toolbox.register(&#34;select&#34;, tools.selTournament, tournsize=5)  # Selection
    toolbox.register(&#34;map&#34;, futures.map)  # So that we can use scoop

    # DO: May want to later do a different selection process

    # We choose the parameters, for the most part, random
    algo_instance = algo_constructor()
    params = algo_instance.params

    for key in params.pkeys:
        toolbox.register(key, random.choice, params.ranges[key])

    func_seq = []
    for key in params.pkeys:
        func_seq.append(getattr(toolbox, key))

    # Here we populate our individual with all of the parameters
    toolbox.register(&#34;individual&#34;, tools.initCycle,
                     creator.Individual, func_seq, n=1)

    # And we make our population
    toolbox.register(&#34;population&#34;, tools.initRepeat,
                     list, toolbox.individual, n=pop_size)

    return toolbox


def initIndividual(icls, content):
    &#34;&#34;&#34;Create a new individual.&#34;&#34;&#34;
    logging.getLogger().info(f&#34;In initIndividual={content}&#34;)
    return icls(content)


def initPopulation(pcls, ind_init, filename):
    &#34;&#34;&#34;Create a population by initializing our specified number of individuals.&#34;&#34;&#34;
    with open(filename, &#34;r&#34;) as pop_file:
        contents = json.load(pop_file)
    return pcls(ind_init(c) for c in contents)


class Evolver(object):
    &#34;&#34;&#34;Perform the genetic algorithm by initializing a population and evolving it over a
     specified number of generations to find the optimal algorithm and parameters for the problem.

    Functions:
    newpopulation -- Initialize a new population.
    writepop -- Records our population in the file &#34;filename&#34;.
    readpop -- Reads in existing population from &#34;filename&#34;.
    popfitness -- Calculates the fitness values for our population.
    mutate -- Performs mutation and crossover on population.
    nextgen -- Generates the next generation of our population.
    run -- Runs the genetic algorithm.

    &#34;&#34;&#34;

#     AllVals = []
# #     my_p=param_space
#     for key in my_p.pkeys:
#         AllVals.append(my_p.ranges[key])

    def __init__(self, algo_constructor, data, pop_size=10):
        &#34;&#34;&#34;Set default values for the variables.

        Keyword arguments:
        img -- The original training image
        mask -- The ground truth segmentation mask for the img
        pop_size -- Integer value denoting size of our population,
            or how many individuals there are (default 10)

        &#34;&#34;&#34;
        # Build Population based on size
        self.data = data
        self.algo_constructor = algo_constructor
        self.tool = makeToolbox(pop_size, algo_constructor)
        self.hof = deap.tools.HallOfFame(10)
        self.best_avgs = []
        self.gen = 0
        self.cxpb, self.mutpb, self.flip_prob = 0.9, 0.9, 0.9

    def newpopulation(self):
        &#34;&#34;&#34;Initialize a new population.&#34;&#34;&#34;
        return self.tool.population()

    def writepop(self, tpop, filename=&#39;test.json&#39;):
        &#34;&#34;&#34;Record the population in the file &#34;filename&#34;.

        Keyword arguments:
        tpop -- The population to be recorded.
        filename -- string denoting file in which to record
            the population. (default &#39;test.json&#39;)

        &#34;&#34;&#34;
        logging.getLogger().info(f&#34;Writting population to {filename}&#34;)
        with open(filename, &#39;w&#39;) as outfile:
            json.dump(tpop, outfile)

    def readpop(self, filename=&#39;test.json&#39;):
        &#34;&#34;&#34;Read in existing population from &#34;filename&#34;.&#34;&#34;&#34;

        logging.getLogger().info(f&#34;Reading population from {filename}&#34;)
        self.tool.register(&#34;population_read&#34;, initPopulation,
                           list, creator.Individual, filename)

        self.tool.register(&#34;individual_guess&#34;,
                           initIndividual, creator.Individual)

        self.tool.register(&#34;population_guess&#34;, initPopulation,
                           list, self.tool.individual_guess, &#34;my_guess.json&#34;)

        return self.tool.population_read()

    def popfitness(self, tpop):
        &#34;&#34;&#34;Calculate the fitness values for the population, and log general statistics about these
         values. Uses hall of fame (hof) to keep track of top 10 individuals.

        Keyword arguments:
        tpop -- current population

        Outputs:
        extract_fits -- Fitness values for our population
        tpop -- current population

        &#34;&#34;&#34;
        # make copies of self.data
        data_references = [copy.deepcopy(self.data)
                           for i in range(0, len(tpop))]
        algos = [self.algo_constructor(paramlist=list(ind)) for ind in tpop]

        # Map the evaluation command to reference data and then to population list
        outdata = map(self.tool.evaluate, algos, data_references)

        # Loop though outputs and add them to ind.fitness so we have a complete record.
        for ind, data in zip(tpop, outdata):
            print(f&#34;fitness={data.fitness}\n&#34;)
            ind.fitness.values = [data.fitness]
        extract_fits = [ind.fitness.values[0] for ind in tpop]

        self.hof.update(tpop)

        #Algo = AlgorithmSpace(AlgoParams)

        # Evaluating the new population
        leng = len(tpop)
        mean = sum(extract_fits) / leng
        self.best_avgs.append(mean)
        sum1 = sum(i*i for i in extract_fits)
        stdev = abs(sum1 / leng - mean ** 2) ** 0.5
        logging.getLogger().info(f&#34;Generation: {self.gen}&#34;)
        logging.getLogger().info(f&#34; Min: {min(extract_fits)}&#34;)
        logging.getLogger().info(f&#34; Max: {max(extract_fits)}&#34;)
        logging.getLogger().info(f&#34; Avg: {mean}&#34;)
        logging.getLogger().info(f&#34; Std: {stdev}&#34;)
        logging.getLogger().info(f&#34; Size: {leng}&#34;)
        #logging.info(&#34; Time: &#34;, time.time() - initTime)
        logging.getLogger().info(f&#34;Best Fitness: {self.hof[0].fitness.values}&#34;)
        logging.getLogger().info(f&#34;{self.hof[0]}&#34;)
        # Did we improve the population?
        # past_pop = tpop
        # past_min = min(extract_fits)
        # past_mean = mean

        self.gen += self.gen

        return extract_fits, tpop

    def mutate(self, tpop, keep_prob=0.1, mutate_prob=0.4):
        &#34;&#34;&#34;Return new population with mutated individuals. Perform both mutation and crossover.

        Keyword arguments:
        tpop -- current population

        Output:
        final -- new population with mutated individuals.

       &#34;&#34;&#34;
        # Calculate next population

        # TODO: There is an error here. We need to make sure the best hof is included?

        my_sz = len(tpop)  # Length of current population
        top = min(10, max(1, round(keep_prob * my_sz)))
        top = min(top, len(self.hof))
        var = max(1, round(mutate_prob * my_sz))
        var = min(var, len(self.hof))
        ran = my_sz - top - var

#         print(f&#34;pop[0:{top}:{var}:{ran}]&#34;)
#         print(f&#34;pop[0:{top}:{top+var}:{my_sz}]&#34;)

#         offspring = self.tool.select(tpop, var)
#         offspring = list(map(self.tool.clone, offspring))  # original code

        offspring = copy.deepcopy(list(self.hof))

        # crossover
        for child1, child2 in zip(offspring[::2], offspring[1::2]):
            # Do we crossover?
            if random.random() &lt; self.cxpb:
                self.tool.mate(child1, child2)
                # The parents may be okay values so we should keep them
                # in the set
                del child1.fitness.values
                del child2.fitness.values

        # mutation
        for mutant in offspring:
            if random.random() &lt; self.mutpb:
                self.tool.mutate(self.algo_constructor, mutant, self.flip_prob)
                del mutant.fitness.values

        # new
        #population = self.newpopulation()
        pop = self.tool.population()

        final = pop[0:ran]
        #print(f&#34;pop size should be {len(final)}&#34;)
        final += self.hof[0:top]
        #print(f&#34;pop size should be {len(final)}&#34;)
        final += offspring[0:var]
        #print(f&#34;pop size should be {len(final)}&#34;)

        # print(f&#34;pop[0:{top}:{var}:{ran}]&#34;)
        #print(f&#34;pop size should be {len(final)}&#34;)

        # Replacing the old population
        return final

    def nextgen(self, tpop):
        &#34;&#34;&#34;Generate the next generation of the population.

        Keyword arguments:
        tpop -- current population

        &#34;&#34;&#34;
        _, tpop = self.popfitness(tpop)
        return self.mutate(tpop)

    def run(self, ngen=10, population=None, startfile=None, checkpoint=None, cp_freq=1):
        &#34;&#34;&#34;Run the genetic algorithm, updating the population over ngen number of generations.

        Keywork arguments:
        ngen -- number of generations to run the genetic algorithm.
        startfile -- File containing existing population (default None)
        checkpoint -- File containing existing checkpoint (default None)

        Output:
        population -- Resulting population after ngen generations.

        &#34;&#34;&#34;

        if startfile:
            try:
                print(f&#34;Reading in {startfile}&#34;)
                population = self.readpop(startfile)
            except FileNotFoundError:
                print(&#34;WARNING: Start file not found&#34;)
            except:
                raise

        if not population:
            print(f&#34;Initializing a new random population&#34;)
            population = self.newpopulation()
            if checkpoint:
                self.writepop(population, filename=f&#34;{checkpoint}&#34;)

        for cur_g in range(0, ngen+1):
            print(
                f&#34;Generation {cur_g}/{ngen} of population size {len(population)}&#34;)

            _, population = self.popfitness(population)

            bestsofar = self.hof[0]

            # Create a new instance from the current algorithm
            seg = self.algo_constructor(bestsofar)

            self.data = seg.pipe(self.data)
            fitness = self.data.fitness
            print(f&#34;#BEST [{fitness},  {bestsofar}]&#34;)

            if checkpoint and cur_g % cp_freq == 0:
                print(f&#34;Writing Checkpoint file - {checkpoint}&#34;)
                copyfile(f&#34;{checkpoint}&#34;, f&#34;{checkpoint}.prev&#34;)
                self.writepop(population, filename=f&#34;{checkpoint}&#34;)
                for cur_p in range(len(population)):
                    logging.getLogger().info(population[cur_p])
            if cur_g &lt; ngen+1:
                if bestsofar.fitness.values[0] &gt;= 20:
                    population = self.newpopulation()
                  # if the best fitness value is at or above the
                  # threshold of 0.95, discard the entire current
                  # population and randomly select a new population
                  # for the next generation
                  # note: setting keep_prob = 0 and mutate_prob = 1
                  # as mutate arguments
                  # should have same result as self.new_population()
                else:
                    population = self.mutate(population)
                  # if the best fitness value is below this threshold,
                  # proceed as normal, mutating the current population
                  # to get the next generation

        if checkpoint:
            print(f&#34;Writing Checkpoint file - {checkpoint}&#34;)
            copyfile(f&#34;{checkpoint}&#34;, f&#34;{checkpoint}.prev&#34;)
            self.writepop(population, filename=f&#34;{checkpoint}&#34;)
            for cur_p in range(len(population)):
                logging.getLogger().info(population[cur_p])
        return population</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="see.GeneticSearch.initIndividual"><code class="name flex">
<span>def <span class="ident">initIndividual</span></span>(<span>icls, content)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a new individual.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initIndividual(icls, content):
    &#34;&#34;&#34;Create a new individual.&#34;&#34;&#34;
    logging.getLogger().info(f&#34;In initIndividual={content}&#34;)
    return icls(content)</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.initPopulation"><code class="name flex">
<span>def <span class="ident">initPopulation</span></span>(<span>pcls, ind_init, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a population by initializing our specified number of individuals.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initPopulation(pcls, ind_init, filename):
    &#34;&#34;&#34;Create a population by initializing our specified number of individuals.&#34;&#34;&#34;
    with open(filename, &#34;r&#34;) as pop_file:
        contents = json.load(pop_file)
    return pcls(ind_init(c) for c in contents)</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.makeToolbox"><code class="name flex">
<span>def <span class="ident">makeToolbox</span></span>(<span>pop_size, algo_constructor)</span>
</code></dt>
<dd>
<div class="desc"><p>Make a genetic algorithm toolbox using DEAP. The toolbox uses premade functions
for crossover, mutation, evaluation and fitness.</p>
<p>Keyword arguments:
pop_size &ndash; The size of our population, or how many individuals we have</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def makeToolbox(pop_size, algo_constructor):
    &#34;&#34;&#34;Make a genetic algorithm toolbox using DEAP. The toolbox uses premade functions
     for crossover, mutation, evaluation and fitness.

    Keyword arguments:
    pop_size -- The size of our population, or how many individuals we have

    &#34;&#34;&#34;
    # Minimizing fitness function
    creator.create(&#34;FitnessMin&#34;, base.Fitness, weights=(-0.000001,))
    creator.create(&#34;Individual&#34;, list, fitness=creator.FitnessMin)

    # The functions that the GA knows
    toolbox = base.Toolbox()

    # Genetic functions
    toolbox.register(&#34;mate&#34;, skimageCrossRandom)  # crossover
    # toolbox.register(&#34;mutate&#34;, mutate)  # Mutation
    toolbox.register(&#34;mutate&#34;, base_classes.mutateAlgo)  # Mutation
    toolbox.register(&#34;evaluate&#34;, algo_constructor.runAlgo)  # Fitness
    toolbox.register(&#34;select&#34;, tools.selTournament, tournsize=5)  # Selection
    toolbox.register(&#34;map&#34;, futures.map)  # So that we can use scoop

    # DO: May want to later do a different selection process

    # We choose the parameters, for the most part, random
    algo_instance = algo_constructor()
    params = algo_instance.params

    for key in params.pkeys:
        toolbox.register(key, random.choice, params.ranges[key])

    func_seq = []
    for key in params.pkeys:
        func_seq.append(getattr(toolbox, key))

    # Here we populate our individual with all of the parameters
    toolbox.register(&#34;individual&#34;, tools.initCycle,
                     creator.Individual, func_seq, n=1)

    # And we make our population
    toolbox.register(&#34;population&#34;, tools.initRepeat,
                     list, toolbox.individual, n=pop_size)

    return toolbox</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.mutate"><code class="name flex">
<span>def <span class="ident">mutate</span></span>(<span>copy_child, pos_vals, flip_prob=0.5, seed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Change a few of the parameters of the weighting a random number against the flip_prob.</p>
<p>Keyword arguments:
copy_child &ndash; the individual to mutate.
pos_vals &ndash; list of lists where each list are the possible
values for that particular parameter.
flip_prob &ndash; how likely it is that we will mutate each value.
It is computed seperately for each value.</p>
<p>Outputs:
child &ndash; New, possibly mutated, individual.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mutate(copy_child, pos_vals, flip_prob=0.5, seed=False):
    &#34;&#34;&#34;Change a few of the parameters of the weighting a random number against the flip_prob.

    Keyword arguments:
    copy_child -- the individual to mutate.
    pos_vals -- list of lists where each list are the possible
                values for that particular parameter.
    flip_prob -- how likely it is that we will mutate each value.
                It is computed seperately for each value.

    Outputs:
    child -- New, possibly mutated, individual.

    &#34;&#34;&#34;
    # Just because we chose to mutate a value doesn&#39;t mean we mutate
    # Every aspect of the value
    child = copy.deepcopy(copy_child)

    # Not every algorithm is associated with every value
    # Let&#39;s first see if we change the algorithm
    rand_val = random.random()
    if rand_val &lt; flip_prob:
        # Let&#39;s mutate
        child[0] = random.choice(pos_vals[0])
    # Now let&#39;s get the indexes (parameters) related to that value
    #switcher = AlgoHelp().algoIndexes()
    #indexes = switcher.get(child[0])

    for index in range(len(pos_vals)):
        rand_val = random.random()
        if rand_val &lt; flip_prob:
            #             # Then we mutate said value
            #             if index == 22:
            #                 # Do some special
            #                 my_x = random.choice(pos_vals[22])
            #                 my_y = random.choice(pos_vals[23])
            #                 my_z = random.choice(pos_vals[24])
            #                 child[index] = (my_x, my_y, my_z)
            #                 continue
            child[index] = random.choice(pos_vals[index])
    return child</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.skimageCrossRandom"><code class="name flex">
<span>def <span class="ident">skimageCrossRandom</span></span>(<span>np1, np2, seed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute a crossover between two arrays (np1 and np2) picking a random
amount of indexes to change between the two.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def skimageCrossRandom(np1, np2, seed=False):
    &#34;&#34;&#34;Execute a crossover between two arrays (np1 and np2) picking a random
     amount of indexes to change between the two.&#34;&#34;&#34;
    if seed == True:
        random.seed(0)
    # DO: Only change values associated with algorithm
    assert len(np1) == len(np2)
    # The number of places that we&#39;ll cross
    crosses = random.randrange(len(np1))
    # We pick that many crossing points
    indexes = random.sample(range(0, len(np1)), crosses)
    # And at those crossing points, we switch the parameters

    for i in indexes:
        np1[i], np2[i] = np2[i], np1[i]

    return np1, np2</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.twoPointCopy"><code class="name flex">
<span>def <span class="ident">twoPointCopy</span></span>(<span>np1, np2, seed=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute a crossover between two numpy arrays of the same length.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def twoPointCopy(np1, np2, seed=False):
    &#34;&#34;&#34;Execute a crossover between two numpy arrays of the same length.&#34;&#34;&#34;
    if seed == True:
        random.seed(0)
    assert len(np1) == len(np2)
    size = len(np1)
    point1 = random.randint(1, size)
    point2 = random.randint(1, size - 1)
    if point2 &gt;= point1:
        point2 += 1
    else:  # Swap the two points
        point1, point2 = point2, point1
    np1[point1:point2], np2[point1:point2] = np2[point1:point2].copy(
    ), np1[point1:point2].copy()
    return np1, np2</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="see.GeneticSearch.Evolver"><code class="flex name class">
<span>class <span class="ident">Evolver</span></span>
<span>(</span><span>algo_constructor, data, pop_size=10)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the genetic algorithm by initializing a population and evolving it over a
specified number of generations to find the optimal algorithm and parameters for the problem.</p>
<p>Functions:
newpopulation &ndash; Initialize a new population.
writepop &ndash; Records our population in the file "filename".
readpop &ndash; Reads in existing population from "filename".
popfitness &ndash; Calculates the fitness values for our population.
mutate &ndash; Performs mutation and crossover on population.
nextgen &ndash; Generates the next generation of our population.
run &ndash; Runs the genetic algorithm.</p>
<p>Set default values for the variables.</p>
<p>Keyword arguments:
img &ndash; The original training image
mask &ndash; The ground truth segmentation mask for the img
pop_size &ndash; Integer value denoting size of our population,
or how many individuals there are (default 10)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Evolver(object):
    &#34;&#34;&#34;Perform the genetic algorithm by initializing a population and evolving it over a
     specified number of generations to find the optimal algorithm and parameters for the problem.

    Functions:
    newpopulation -- Initialize a new population.
    writepop -- Records our population in the file &#34;filename&#34;.
    readpop -- Reads in existing population from &#34;filename&#34;.
    popfitness -- Calculates the fitness values for our population.
    mutate -- Performs mutation and crossover on population.
    nextgen -- Generates the next generation of our population.
    run -- Runs the genetic algorithm.

    &#34;&#34;&#34;

#     AllVals = []
# #     my_p=param_space
#     for key in my_p.pkeys:
#         AllVals.append(my_p.ranges[key])

    def __init__(self, algo_constructor, data, pop_size=10):
        &#34;&#34;&#34;Set default values for the variables.

        Keyword arguments:
        img -- The original training image
        mask -- The ground truth segmentation mask for the img
        pop_size -- Integer value denoting size of our population,
            or how many individuals there are (default 10)

        &#34;&#34;&#34;
        # Build Population based on size
        self.data = data
        self.algo_constructor = algo_constructor
        self.tool = makeToolbox(pop_size, algo_constructor)
        self.hof = deap.tools.HallOfFame(10)
        self.best_avgs = []
        self.gen = 0
        self.cxpb, self.mutpb, self.flip_prob = 0.9, 0.9, 0.9

    def newpopulation(self):
        &#34;&#34;&#34;Initialize a new population.&#34;&#34;&#34;
        return self.tool.population()

    def writepop(self, tpop, filename=&#39;test.json&#39;):
        &#34;&#34;&#34;Record the population in the file &#34;filename&#34;.

        Keyword arguments:
        tpop -- The population to be recorded.
        filename -- string denoting file in which to record
            the population. (default &#39;test.json&#39;)

        &#34;&#34;&#34;
        logging.getLogger().info(f&#34;Writting population to {filename}&#34;)
        with open(filename, &#39;w&#39;) as outfile:
            json.dump(tpop, outfile)

    def readpop(self, filename=&#39;test.json&#39;):
        &#34;&#34;&#34;Read in existing population from &#34;filename&#34;.&#34;&#34;&#34;

        logging.getLogger().info(f&#34;Reading population from {filename}&#34;)
        self.tool.register(&#34;population_read&#34;, initPopulation,
                           list, creator.Individual, filename)

        self.tool.register(&#34;individual_guess&#34;,
                           initIndividual, creator.Individual)

        self.tool.register(&#34;population_guess&#34;, initPopulation,
                           list, self.tool.individual_guess, &#34;my_guess.json&#34;)

        return self.tool.population_read()

    def popfitness(self, tpop):
        &#34;&#34;&#34;Calculate the fitness values for the population, and log general statistics about these
         values. Uses hall of fame (hof) to keep track of top 10 individuals.

        Keyword arguments:
        tpop -- current population

        Outputs:
        extract_fits -- Fitness values for our population
        tpop -- current population

        &#34;&#34;&#34;
        # make copies of self.data
        data_references = [copy.deepcopy(self.data)
                           for i in range(0, len(tpop))]
        algos = [self.algo_constructor(paramlist=list(ind)) for ind in tpop]

        # Map the evaluation command to reference data and then to population list
        outdata = map(self.tool.evaluate, algos, data_references)

        # Loop though outputs and add them to ind.fitness so we have a complete record.
        for ind, data in zip(tpop, outdata):
            print(f&#34;fitness={data.fitness}\n&#34;)
            ind.fitness.values = [data.fitness]
        extract_fits = [ind.fitness.values[0] for ind in tpop]

        self.hof.update(tpop)

        #Algo = AlgorithmSpace(AlgoParams)

        # Evaluating the new population
        leng = len(tpop)
        mean = sum(extract_fits) / leng
        self.best_avgs.append(mean)
        sum1 = sum(i*i for i in extract_fits)
        stdev = abs(sum1 / leng - mean ** 2) ** 0.5
        logging.getLogger().info(f&#34;Generation: {self.gen}&#34;)
        logging.getLogger().info(f&#34; Min: {min(extract_fits)}&#34;)
        logging.getLogger().info(f&#34; Max: {max(extract_fits)}&#34;)
        logging.getLogger().info(f&#34; Avg: {mean}&#34;)
        logging.getLogger().info(f&#34; Std: {stdev}&#34;)
        logging.getLogger().info(f&#34; Size: {leng}&#34;)
        #logging.info(&#34; Time: &#34;, time.time() - initTime)
        logging.getLogger().info(f&#34;Best Fitness: {self.hof[0].fitness.values}&#34;)
        logging.getLogger().info(f&#34;{self.hof[0]}&#34;)
        # Did we improve the population?
        # past_pop = tpop
        # past_min = min(extract_fits)
        # past_mean = mean

        self.gen += self.gen

        return extract_fits, tpop

    def mutate(self, tpop, keep_prob=0.1, mutate_prob=0.4):
        &#34;&#34;&#34;Return new population with mutated individuals. Perform both mutation and crossover.

        Keyword arguments:
        tpop -- current population

        Output:
        final -- new population with mutated individuals.

       &#34;&#34;&#34;
        # Calculate next population

        # TODO: There is an error here. We need to make sure the best hof is included?

        my_sz = len(tpop)  # Length of current population
        top = min(10, max(1, round(keep_prob * my_sz)))
        top = min(top, len(self.hof))
        var = max(1, round(mutate_prob * my_sz))
        var = min(var, len(self.hof))
        ran = my_sz - top - var

#         print(f&#34;pop[0:{top}:{var}:{ran}]&#34;)
#         print(f&#34;pop[0:{top}:{top+var}:{my_sz}]&#34;)

#         offspring = self.tool.select(tpop, var)
#         offspring = list(map(self.tool.clone, offspring))  # original code

        offspring = copy.deepcopy(list(self.hof))

        # crossover
        for child1, child2 in zip(offspring[::2], offspring[1::2]):
            # Do we crossover?
            if random.random() &lt; self.cxpb:
                self.tool.mate(child1, child2)
                # The parents may be okay values so we should keep them
                # in the set
                del child1.fitness.values
                del child2.fitness.values

        # mutation
        for mutant in offspring:
            if random.random() &lt; self.mutpb:
                self.tool.mutate(self.algo_constructor, mutant, self.flip_prob)
                del mutant.fitness.values

        # new
        #population = self.newpopulation()
        pop = self.tool.population()

        final = pop[0:ran]
        #print(f&#34;pop size should be {len(final)}&#34;)
        final += self.hof[0:top]
        #print(f&#34;pop size should be {len(final)}&#34;)
        final += offspring[0:var]
        #print(f&#34;pop size should be {len(final)}&#34;)

        # print(f&#34;pop[0:{top}:{var}:{ran}]&#34;)
        #print(f&#34;pop size should be {len(final)}&#34;)

        # Replacing the old population
        return final

    def nextgen(self, tpop):
        &#34;&#34;&#34;Generate the next generation of the population.

        Keyword arguments:
        tpop -- current population

        &#34;&#34;&#34;
        _, tpop = self.popfitness(tpop)
        return self.mutate(tpop)

    def run(self, ngen=10, population=None, startfile=None, checkpoint=None, cp_freq=1):
        &#34;&#34;&#34;Run the genetic algorithm, updating the population over ngen number of generations.

        Keywork arguments:
        ngen -- number of generations to run the genetic algorithm.
        startfile -- File containing existing population (default None)
        checkpoint -- File containing existing checkpoint (default None)

        Output:
        population -- Resulting population after ngen generations.

        &#34;&#34;&#34;

        if startfile:
            try:
                print(f&#34;Reading in {startfile}&#34;)
                population = self.readpop(startfile)
            except FileNotFoundError:
                print(&#34;WARNING: Start file not found&#34;)
            except:
                raise

        if not population:
            print(f&#34;Initializing a new random population&#34;)
            population = self.newpopulation()
            if checkpoint:
                self.writepop(population, filename=f&#34;{checkpoint}&#34;)

        for cur_g in range(0, ngen+1):
            print(
                f&#34;Generation {cur_g}/{ngen} of population size {len(population)}&#34;)

            _, population = self.popfitness(population)

            bestsofar = self.hof[0]

            # Create a new instance from the current algorithm
            seg = self.algo_constructor(bestsofar)

            self.data = seg.pipe(self.data)
            fitness = self.data.fitness
            print(f&#34;#BEST [{fitness},  {bestsofar}]&#34;)

            if checkpoint and cur_g % cp_freq == 0:
                print(f&#34;Writing Checkpoint file - {checkpoint}&#34;)
                copyfile(f&#34;{checkpoint}&#34;, f&#34;{checkpoint}.prev&#34;)
                self.writepop(population, filename=f&#34;{checkpoint}&#34;)
                for cur_p in range(len(population)):
                    logging.getLogger().info(population[cur_p])
            if cur_g &lt; ngen+1:
                if bestsofar.fitness.values[0] &gt;= 20:
                    population = self.newpopulation()
                  # if the best fitness value is at or above the
                  # threshold of 0.95, discard the entire current
                  # population and randomly select a new population
                  # for the next generation
                  # note: setting keep_prob = 0 and mutate_prob = 1
                  # as mutate arguments
                  # should have same result as self.new_population()
                else:
                    population = self.mutate(population)
                  # if the best fitness value is below this threshold,
                  # proceed as normal, mutating the current population
                  # to get the next generation

        if checkpoint:
            print(f&#34;Writing Checkpoint file - {checkpoint}&#34;)
            copyfile(f&#34;{checkpoint}&#34;, f&#34;{checkpoint}.prev&#34;)
            self.writepop(population, filename=f&#34;{checkpoint}&#34;)
            for cur_p in range(len(population)):
                logging.getLogger().info(population[cur_p])
        return population</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="see.GeneticSearch.Evolver.mutate"><code class="name flex">
<span>def <span class="ident">mutate</span></span>(<span>self, tpop, keep_prob=0.1, mutate_prob=0.4)</span>
</code></dt>
<dd>
<div class="desc"><p>Return new population with mutated individuals. Perform both mutation and crossover.</p>
<p>Keyword arguments:
tpop &ndash; current population</p>
<p>Output:
final &ndash; new population with mutated individuals.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def mutate(self, tpop, keep_prob=0.1, mutate_prob=0.4):
        &#34;&#34;&#34;Return new population with mutated individuals. Perform both mutation and crossover.

        Keyword arguments:
        tpop -- current population

        Output:
        final -- new population with mutated individuals.

       &#34;&#34;&#34;
        # Calculate next population

        # TODO: There is an error here. We need to make sure the best hof is included?

        my_sz = len(tpop)  # Length of current population
        top = min(10, max(1, round(keep_prob * my_sz)))
        top = min(top, len(self.hof))
        var = max(1, round(mutate_prob * my_sz))
        var = min(var, len(self.hof))
        ran = my_sz - top - var

#         print(f&#34;pop[0:{top}:{var}:{ran}]&#34;)
#         print(f&#34;pop[0:{top}:{top+var}:{my_sz}]&#34;)

#         offspring = self.tool.select(tpop, var)
#         offspring = list(map(self.tool.clone, offspring))  # original code

        offspring = copy.deepcopy(list(self.hof))

        # crossover
        for child1, child2 in zip(offspring[::2], offspring[1::2]):
            # Do we crossover?
            if random.random() &lt; self.cxpb:
                self.tool.mate(child1, child2)
                # The parents may be okay values so we should keep them
                # in the set
                del child1.fitness.values
                del child2.fitness.values

        # mutation
        for mutant in offspring:
            if random.random() &lt; self.mutpb:
                self.tool.mutate(self.algo_constructor, mutant, self.flip_prob)
                del mutant.fitness.values

        # new
        #population = self.newpopulation()
        pop = self.tool.population()

        final = pop[0:ran]
        #print(f&#34;pop size should be {len(final)}&#34;)
        final += self.hof[0:top]
        #print(f&#34;pop size should be {len(final)}&#34;)
        final += offspring[0:var]
        #print(f&#34;pop size should be {len(final)}&#34;)

        # print(f&#34;pop[0:{top}:{var}:{ran}]&#34;)
        #print(f&#34;pop size should be {len(final)}&#34;)

        # Replacing the old population
        return final</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.Evolver.newpopulation"><code class="name flex">
<span>def <span class="ident">newpopulation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize a new population.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def newpopulation(self):
    &#34;&#34;&#34;Initialize a new population.&#34;&#34;&#34;
    return self.tool.population()</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.Evolver.nextgen"><code class="name flex">
<span>def <span class="ident">nextgen</span></span>(<span>self, tpop)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate the next generation of the population.</p>
<p>Keyword arguments:
tpop &ndash; current population</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nextgen(self, tpop):
    &#34;&#34;&#34;Generate the next generation of the population.

    Keyword arguments:
    tpop -- current population

    &#34;&#34;&#34;
    _, tpop = self.popfitness(tpop)
    return self.mutate(tpop)</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.Evolver.popfitness"><code class="name flex">
<span>def <span class="ident">popfitness</span></span>(<span>self, tpop)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the fitness values for the population, and log general statistics about these
values. Uses hall of fame (hof) to keep track of top 10 individuals.</p>
<p>Keyword arguments:
tpop &ndash; current population</p>
<p>Outputs:
extract_fits &ndash; Fitness values for our population
tpop &ndash; current population</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def popfitness(self, tpop):
    &#34;&#34;&#34;Calculate the fitness values for the population, and log general statistics about these
     values. Uses hall of fame (hof) to keep track of top 10 individuals.

    Keyword arguments:
    tpop -- current population

    Outputs:
    extract_fits -- Fitness values for our population
    tpop -- current population

    &#34;&#34;&#34;
    # make copies of self.data
    data_references = [copy.deepcopy(self.data)
                       for i in range(0, len(tpop))]
    algos = [self.algo_constructor(paramlist=list(ind)) for ind in tpop]

    # Map the evaluation command to reference data and then to population list
    outdata = map(self.tool.evaluate, algos, data_references)

    # Loop though outputs and add them to ind.fitness so we have a complete record.
    for ind, data in zip(tpop, outdata):
        print(f&#34;fitness={data.fitness}\n&#34;)
        ind.fitness.values = [data.fitness]
    extract_fits = [ind.fitness.values[0] for ind in tpop]

    self.hof.update(tpop)

    #Algo = AlgorithmSpace(AlgoParams)

    # Evaluating the new population
    leng = len(tpop)
    mean = sum(extract_fits) / leng
    self.best_avgs.append(mean)
    sum1 = sum(i*i for i in extract_fits)
    stdev = abs(sum1 / leng - mean ** 2) ** 0.5
    logging.getLogger().info(f&#34;Generation: {self.gen}&#34;)
    logging.getLogger().info(f&#34; Min: {min(extract_fits)}&#34;)
    logging.getLogger().info(f&#34; Max: {max(extract_fits)}&#34;)
    logging.getLogger().info(f&#34; Avg: {mean}&#34;)
    logging.getLogger().info(f&#34; Std: {stdev}&#34;)
    logging.getLogger().info(f&#34; Size: {leng}&#34;)
    #logging.info(&#34; Time: &#34;, time.time() - initTime)
    logging.getLogger().info(f&#34;Best Fitness: {self.hof[0].fitness.values}&#34;)
    logging.getLogger().info(f&#34;{self.hof[0]}&#34;)
    # Did we improve the population?
    # past_pop = tpop
    # past_min = min(extract_fits)
    # past_mean = mean

    self.gen += self.gen

    return extract_fits, tpop</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.Evolver.readpop"><code class="name flex">
<span>def <span class="ident">readpop</span></span>(<span>self, filename='test.json')</span>
</code></dt>
<dd>
<div class="desc"><p>Read in existing population from "filename".</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readpop(self, filename=&#39;test.json&#39;):
    &#34;&#34;&#34;Read in existing population from &#34;filename&#34;.&#34;&#34;&#34;

    logging.getLogger().info(f&#34;Reading population from {filename}&#34;)
    self.tool.register(&#34;population_read&#34;, initPopulation,
                       list, creator.Individual, filename)

    self.tool.register(&#34;individual_guess&#34;,
                       initIndividual, creator.Individual)

    self.tool.register(&#34;population_guess&#34;, initPopulation,
                       list, self.tool.individual_guess, &#34;my_guess.json&#34;)

    return self.tool.population_read()</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.Evolver.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, ngen=10, population=None, startfile=None, checkpoint=None, cp_freq=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Run the genetic algorithm, updating the population over ngen number of generations.</p>
<p>Keywork arguments:
ngen &ndash; number of generations to run the genetic algorithm.
startfile &ndash; File containing existing population (default None)
checkpoint &ndash; File containing existing checkpoint (default None)</p>
<p>Output:
population &ndash; Resulting population after ngen generations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, ngen=10, population=None, startfile=None, checkpoint=None, cp_freq=1):
    &#34;&#34;&#34;Run the genetic algorithm, updating the population over ngen number of generations.

    Keywork arguments:
    ngen -- number of generations to run the genetic algorithm.
    startfile -- File containing existing population (default None)
    checkpoint -- File containing existing checkpoint (default None)

    Output:
    population -- Resulting population after ngen generations.

    &#34;&#34;&#34;

    if startfile:
        try:
            print(f&#34;Reading in {startfile}&#34;)
            population = self.readpop(startfile)
        except FileNotFoundError:
            print(&#34;WARNING: Start file not found&#34;)
        except:
            raise

    if not population:
        print(f&#34;Initializing a new random population&#34;)
        population = self.newpopulation()
        if checkpoint:
            self.writepop(population, filename=f&#34;{checkpoint}&#34;)

    for cur_g in range(0, ngen+1):
        print(
            f&#34;Generation {cur_g}/{ngen} of population size {len(population)}&#34;)

        _, population = self.popfitness(population)

        bestsofar = self.hof[0]

        # Create a new instance from the current algorithm
        seg = self.algo_constructor(bestsofar)

        self.data = seg.pipe(self.data)
        fitness = self.data.fitness
        print(f&#34;#BEST [{fitness},  {bestsofar}]&#34;)

        if checkpoint and cur_g % cp_freq == 0:
            print(f&#34;Writing Checkpoint file - {checkpoint}&#34;)
            copyfile(f&#34;{checkpoint}&#34;, f&#34;{checkpoint}.prev&#34;)
            self.writepop(population, filename=f&#34;{checkpoint}&#34;)
            for cur_p in range(len(population)):
                logging.getLogger().info(population[cur_p])
        if cur_g &lt; ngen+1:
            if bestsofar.fitness.values[0] &gt;= 20:
                population = self.newpopulation()
              # if the best fitness value is at or above the
              # threshold of 0.95, discard the entire current
              # population and randomly select a new population
              # for the next generation
              # note: setting keep_prob = 0 and mutate_prob = 1
              # as mutate arguments
              # should have same result as self.new_population()
            else:
                population = self.mutate(population)
              # if the best fitness value is below this threshold,
              # proceed as normal, mutating the current population
              # to get the next generation

    if checkpoint:
        print(f&#34;Writing Checkpoint file - {checkpoint}&#34;)
        copyfile(f&#34;{checkpoint}&#34;, f&#34;{checkpoint}.prev&#34;)
        self.writepop(population, filename=f&#34;{checkpoint}&#34;)
        for cur_p in range(len(population)):
            logging.getLogger().info(population[cur_p])
    return population</code></pre>
</details>
</dd>
<dt id="see.GeneticSearch.Evolver.writepop"><code class="name flex">
<span>def <span class="ident">writepop</span></span>(<span>self, tpop, filename='test.json')</span>
</code></dt>
<dd>
<div class="desc"><p>Record the population in the file "filename".</p>
<p>Keyword arguments:
tpop &ndash; The population to be recorded.
filename &ndash; string denoting file in which to record
the population. (default 'test.json')</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def writepop(self, tpop, filename=&#39;test.json&#39;):
    &#34;&#34;&#34;Record the population in the file &#34;filename&#34;.

    Keyword arguments:
    tpop -- The population to be recorded.
    filename -- string denoting file in which to record
        the population. (default &#39;test.json&#39;)

    &#34;&#34;&#34;
    logging.getLogger().info(f&#34;Writting population to {filename}&#34;)
    with open(filename, &#39;w&#39;) as outfile:
        json.dump(tpop, outfile)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="see" href="index.html">see</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="see.GeneticSearch.initIndividual" href="#see.GeneticSearch.initIndividual">initIndividual</a></code></li>
<li><code><a title="see.GeneticSearch.initPopulation" href="#see.GeneticSearch.initPopulation">initPopulation</a></code></li>
<li><code><a title="see.GeneticSearch.makeToolbox" href="#see.GeneticSearch.makeToolbox">makeToolbox</a></code></li>
<li><code><a title="see.GeneticSearch.mutate" href="#see.GeneticSearch.mutate">mutate</a></code></li>
<li><code><a title="see.GeneticSearch.skimageCrossRandom" href="#see.GeneticSearch.skimageCrossRandom">skimageCrossRandom</a></code></li>
<li><code><a title="see.GeneticSearch.twoPointCopy" href="#see.GeneticSearch.twoPointCopy">twoPointCopy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="see.GeneticSearch.Evolver" href="#see.GeneticSearch.Evolver">Evolver</a></code></h4>
<ul class="two-column">
<li><code><a title="see.GeneticSearch.Evolver.mutate" href="#see.GeneticSearch.Evolver.mutate">mutate</a></code></li>
<li><code><a title="see.GeneticSearch.Evolver.newpopulation" href="#see.GeneticSearch.Evolver.newpopulation">newpopulation</a></code></li>
<li><code><a title="see.GeneticSearch.Evolver.nextgen" href="#see.GeneticSearch.Evolver.nextgen">nextgen</a></code></li>
<li><code><a title="see.GeneticSearch.Evolver.popfitness" href="#see.GeneticSearch.Evolver.popfitness">popfitness</a></code></li>
<li><code><a title="see.GeneticSearch.Evolver.readpop" href="#see.GeneticSearch.Evolver.readpop">readpop</a></code></li>
<li><code><a title="see.GeneticSearch.Evolver.run" href="#see.GeneticSearch.Evolver.run">run</a></code></li>
<li><code><a title="see.GeneticSearch.Evolver.writepop" href="#see.GeneticSearch.Evolver.writepop">writepop</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>