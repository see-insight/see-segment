<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>see.Segment_Fitness API documentation</title>
<meta name="description" content="File Segment_Fitness.py." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>see.Segment_Fitness</code></h1>
</header>
<section id="section-intro">
<p>File Segment_Fitness.py.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;File Segment_Fitness.py.&#34;&#34;&#34;

import sys
from skimage import color
import numpy as np

from see.base_classes import algorithm

def countMatches(inferred, ground_truth):
    &#34;&#34;&#34;Map the segments in the inferred segmentation mask to the ground truth segmentation.
    
     mask, and record the number of pixels in each of these mappings as well as the number
     of segments in both masks.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.
    len(m) -- Number of segments in inferred segmentation mask.
    len(n) -- Number of segments in ground truth segmentation mask.

    &#34;&#34;&#34;
    assert inferred.shape == ground_truth.shape
    m = set()
    n = set()
    setcounts = dict()
    for r in range(inferred.shape[0]):
        for c in range(inferred.shape[1]):
            i_key = inferred[r, c]
            m.add(i_key)
            g_key = ground_truth[r, c]
            n.add(g_key)
            if i_key in setcounts:
                if g_key in setcounts[i_key]:
                    setcounts[i_key][g_key] += 1
                else:
                    setcounts[i_key][g_key] = 1
            else:
                setcounts[i_key] = dict()
                setcounts[i_key][g_key] = 1
    return setcounts, len(m), len(n)

def countsets(setcounts):
    &#34;&#34;&#34;For each inferred set, find the ground truth set it maps the most pixels to.
    
    So we start from the inferred image, and map towards the ground truth image.
    For each i_key, the g_key that it maps the most pixels to is considered True.
    In order to see what ground truth sets have a corresponding set(s) in the
    inferred
    image, we record these &#34;true&#34; g_keys. This number of true g_keys is the value for
    L in our fitness function.

    Keyword arguments:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.

    Outputs:
    (total - p) -- Pixel error.
    L -- Number of ground truth segments that have a mapping in the inferred mask
    best -- True mapping as dictionary.

    &#34;&#34;&#34;
    p = 0
    #L = len(setcounts)

    total = 0
    L_sets = set()

    best = dict()

    for i_key in setcounts:
        my_mx = 0
        mx_key = &#39;&#39;
        for g_key in setcounts[i_key]:
            total += setcounts[i_key][g_key] # add to total pixel count
            if setcounts[i_key][g_key] &gt; my_mx:
                my_mx = setcounts[i_key][g_key]
                # mx_key = i_key
                mx_key = g_key # record mapping with greatest pixel count
        p += my_mx
        # L_sets.add(g_key)
        L_sets.add(mx_key) # add the g_key we consider to be correct
        # best[i_key] = g_key
        best[i_key] = mx_key # record &#34;true&#34; mapping
    L = len(L_sets)
    return total-p, L, best



def FF_Option1(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    error = L*(p + 2)
    
    return [error, ]


def FF_Option2a(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)) 
    
    return [error, ]


def FF_Option2b(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)+1) 
    
    return [error, ]


def FitnessFunction_old(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        print(
            f&#34;WARNING: Fitness bounds exceeded, using Maxsize - {L} &lt; {n} or {error} &lt;= 0 or {error} == np.inf or {error} == np.nan:&#34;
        )
        error = sys.maxsize
        # print(error)
    return [error, ]


def FF_Normal(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

        
    tot_num_pixels = ground_truth.shape[0] * ground_truth.shape[1] 
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    #Normalize:
    p = p/tot_num_pixels
    m = m/tot_num_pixels
    n = n/tot_num_pixels

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        error = sys.maxsize
        # print(error)
    return [error, ]

def FF_ML2DHD(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
     error, m is the number of segments in the inferred mask, and n is the number
       of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    tot_num_pixels = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    error = (p+np.abs(n-m))/(N*M)
            
            
    return [ error, n,m]
def FF_Hamming(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming +=  ground_truth[r,c] != inferred[r,c]
            
    return [hamming/(M*N), ]
def FF_Gamma(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    inferred = inferred &gt; 0
    ground_truth = ground_truth &gt; 0
    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    f = lambda u,v: u+v-(2*u*v)
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming += ground_truth[r,c] != inferred[r,c]
    
    gamma = np.abs(1-(2*hamming/(M*N)))
               
    return [1- gamma, ]

def FF_ML2DHD(inferred, ground_truth):
    # TODO: Rename, figure out meaning of name
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    error = p/TP+np.abs(n-m)/TP
            
            
    return [ error, n,m]

def FF_ML2DHD_V2(inferred, ground_truth):
    # TODO: Rename, figure out meaning of name
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, best = countsets(setcounts)
    
    test = set()
    for key in best:
        test.add(best[key])
        
    if len(test) == 1:
        #Trivial Solution
        #print(f&#34;trivial solution&#34;)
        error = 1;
    else:
        error = (p/TP+np.abs(n-m)/(n+m))**(1-np.abs(n-m)/(n+m))
        
    return [ error, n,m]


def FitnessFunction(inferred, ground_truth):
    &#34;&#34;&#34;Return fitness function result from inferred and ground_truth.
    
    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary
    &#34;&#34;&#34;
    return FF_ML2DHD_V2(inferred, ground_truth)

class segment_fitness(algorithm):
    &#34;&#34;&#34;Contains functions to return result of fitness function.
    
    and run segmentation algorithm
    &#34;&#34;&#34;
    
    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Generate algorithm params from parameter list.&#34;&#34;&#34;
        super(segment_fitness, self).__init__(paramlist)
        
    def evaluate(self, mask, gmask):
        &#34;&#34;&#34;Return result of fitness function with image and its ground truth.
           
        Keyword arguments: 
        mask -- the given image
        gmask -- the ground truth mask image
        &#34;&#34;&#34;        
        return FitnessFunction(mask, gmask)
        
    def pipe(self, data):
        &#34;&#34;&#34;Run segmentation algorithm to get inferred mask.&#34;&#34;&#34;
        data.fitness = self.evaluate(data.mask, data.gmask)[0]
        return data    
    
    
    
    
    
    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="see.Segment_Fitness.FF_Gamma"><code class="name flex">
<span>def <span class="ident">FF_Gamma</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Gamma(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    inferred = inferred &gt; 0
    ground_truth = ground_truth &gt; 0
    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    f = lambda u,v: u+v-(2*u*v)
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming += ground_truth[r,c] != inferred[r,c]
    
    gamma = np.abs(1-(2*hamming/(M*N)))
               
    return [1- gamma, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FF_Hamming"><code class="name flex">
<span>def <span class="ident">FF_Hamming</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Hamming(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    hamming = 0;
    for r in range(M):
        for c in range(N):
            hamming +=  ground_truth[r,c] != inferred[r,c]
            
    return [hamming/(M*N), ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FF_ML2DHD"><code class="name flex">
<span>def <span class="ident">FF_ML2DHD</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_ML2DHD(inferred, ground_truth):
    # TODO: Rename, figure out meaning of name
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    error = p/TP+np.abs(n-m)/TP
            
            
    return [ error, n,m]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FF_ML2DHD_V2"><code class="name flex">
<span>def <span class="ident">FF_ML2DHD_V2</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_ML2DHD_V2(inferred, ground_truth):
    # TODO: Rename, figure out meaning of name
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out
    
    TP = ground_truth.shape[0] * ground_truth.shape[1] 
        
    M = ground_truth.shape[0]
    N = ground_truth.shape[1]
    
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, best = countsets(setcounts)
    
    test = set()
    for key in best:
        test.add(best[key])
        
    if len(test) == 1:
        #Trivial Solution
        #print(f&#34;trivial solution&#34;)
        error = 1;
    else:
        error = (p/TP+np.abs(n-m)/(n+m))**(1-np.abs(n-m)/(n+m))
        
    return [ error, n,m]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FF_Normal"><code class="name flex">
<span>def <span class="ident">FF_Normal</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Normal(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

        
    tot_num_pixels = ground_truth.shape[0] * ground_truth.shape[1] 
    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    
    #Normalize:
    p = p/tot_num_pixels
    m = m/tot_num_pixels
    n = n/tot_num_pixels

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        error = sys.maxsize
        # print(error)
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FF_Option1"><code class="name flex">
<span>def <span class="ident">FF_Option1</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Option1(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)
    error = L*(p + 2)
    
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FF_Option2a"><code class="name flex">
<span>def <span class="ident">FF_Option2a</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Option2a(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)) 
    
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FF_Option2b"><code class="name flex">
<span>def <span class="ident">FF_Option2b</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FF_Option2b(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p+2)**(np.abs(m-n)+1) 
    
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FitnessFunction"><code class="name flex">
<span>def <span class="ident">FitnessFunction</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Return fitness function result from inferred and ground_truth.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FitnessFunction(inferred, ground_truth):
    &#34;&#34;&#34;Return fitness function result from inferred and ground_truth.
    
    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary
    &#34;&#34;&#34;
    return FF_ML2DHD_V2(inferred, ground_truth)</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.FitnessFunction_old"><code class="name flex">
<span>def <span class="ident">FitnessFunction_old</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the fitness for an individual.</p>
<p>Takes in two images and compares
them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
error, m is the number of segments in the inferred mask, and n is the number
of segments in the ground truth mask.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
error &ndash; fitness value as float
best &ndash; true mapping as dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def FitnessFunction_old(inferred, ground_truth):
    &#34;&#34;&#34;Compute the fitness for an individual.
    
    Takes in two images and compares
    them according to the equation (p + 2)^log(|m - n| + 2), where p is the pixel
    error, m is the number of segments in the inferred mask, and n is the number
    of segments in the ground truth mask.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    error -- fitness value as float
    best -- true mapping as dictionary

    &#34;&#34;&#34;
    # makes sure images are in grayscale
    if len(inferred.shape) &gt; 2:
        inferred = color.rgb2gray(inferred)
    if len(ground_truth.shape) &gt; 2:  # comment out
        ground_truth = color.rgb2gray(ground_truth)  # comment out

    # Replace with function to output p an L
    # p - number of pixels not correcly mapped
    # L - Number of correctly mapped sets
    setcounts, m, n = countMatches(inferred, ground_truth)

    #print(setcounts)
    p, L, _ = countsets(setcounts)

    error = (p + 2) ** np.log(abs(m - n) + 2)  # / (L &gt;= n)
    # error = (repeat_count + 2)**(abs(m - n)+1)
    # print(f&#34;TESTING - L={L} &lt; n={n} p={p} m={m} error = {error} &#34;)
    if (L &lt; n) or error &lt;= 0 or error == np.inf or error == np.nan:
        print(
            f&#34;WARNING: Fitness bounds exceeded, using Maxsize - {L} &lt; {n} or {error} &lt;= 0 or {error} == np.inf or {error} == np.nan:&#34;
        )
        error = sys.maxsize
        # print(error)
    return [error, ]</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.countMatches"><code class="name flex">
<span>def <span class="ident">countMatches</span></span>(<span>inferred, ground_truth)</span>
</code></dt>
<dd>
<div class="desc"><p>Map the segments in the inferred segmentation mask to the ground truth segmentation.</p>
<p>mask, and record the number of pixels in each of these mappings as well as the number
of segments in both masks.</p>
<p>Keyword arguments:
inferred &ndash; Resulting segmentation mask from individual.
ground_truth &ndash; Ground truth segmentation mask for training image.</p>
<p>Outputs:
setcounts &ndash; Dictionary of dictionaries containing the number of pixels in
each segment mapping.
len(m) &ndash; Number of segments in inferred segmentation mask.
len(n) &ndash; Number of segments in ground truth segmentation mask.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def countMatches(inferred, ground_truth):
    &#34;&#34;&#34;Map the segments in the inferred segmentation mask to the ground truth segmentation.
    
     mask, and record the number of pixels in each of these mappings as well as the number
     of segments in both masks.

    Keyword arguments:
    inferred -- Resulting segmentation mask from individual.
    ground_truth -- Ground truth segmentation mask for training image.

    Outputs:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.
    len(m) -- Number of segments in inferred segmentation mask.
    len(n) -- Number of segments in ground truth segmentation mask.

    &#34;&#34;&#34;
    assert inferred.shape == ground_truth.shape
    m = set()
    n = set()
    setcounts = dict()
    for r in range(inferred.shape[0]):
        for c in range(inferred.shape[1]):
            i_key = inferred[r, c]
            m.add(i_key)
            g_key = ground_truth[r, c]
            n.add(g_key)
            if i_key in setcounts:
                if g_key in setcounts[i_key]:
                    setcounts[i_key][g_key] += 1
                else:
                    setcounts[i_key][g_key] = 1
            else:
                setcounts[i_key] = dict()
                setcounts[i_key][g_key] = 1
    return setcounts, len(m), len(n)</code></pre>
</details>
</dd>
<dt id="see.Segment_Fitness.countsets"><code class="name flex">
<span>def <span class="ident">countsets</span></span>(<span>setcounts)</span>
</code></dt>
<dd>
<div class="desc"><p>For each inferred set, find the ground truth set it maps the most pixels to.</p>
<p>So we start from the inferred image, and map towards the ground truth image.
For each i_key, the g_key that it maps the most pixels to is considered True.
In order to see what ground truth sets have a corresponding set(s) in the
inferred
image, we record these "true" g_keys. This number of true g_keys is the value for
L in our fitness function.</p>
<p>Keyword arguments:
setcounts &ndash; Dictionary of dictionaries containing the number of pixels in
each segment mapping.</p>
<p>Outputs:
(total - p) &ndash; Pixel error.
L &ndash; Number of ground truth segments that have a mapping in the inferred mask
best &ndash; True mapping as dictionary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def countsets(setcounts):
    &#34;&#34;&#34;For each inferred set, find the ground truth set it maps the most pixels to.
    
    So we start from the inferred image, and map towards the ground truth image.
    For each i_key, the g_key that it maps the most pixels to is considered True.
    In order to see what ground truth sets have a corresponding set(s) in the
    inferred
    image, we record these &#34;true&#34; g_keys. This number of true g_keys is the value for
    L in our fitness function.

    Keyword arguments:
    setcounts -- Dictionary of dictionaries containing the number of pixels in
        each segment mapping.

    Outputs:
    (total - p) -- Pixel error.
    L -- Number of ground truth segments that have a mapping in the inferred mask
    best -- True mapping as dictionary.

    &#34;&#34;&#34;
    p = 0
    #L = len(setcounts)

    total = 0
    L_sets = set()

    best = dict()

    for i_key in setcounts:
        my_mx = 0
        mx_key = &#39;&#39;
        for g_key in setcounts[i_key]:
            total += setcounts[i_key][g_key] # add to total pixel count
            if setcounts[i_key][g_key] &gt; my_mx:
                my_mx = setcounts[i_key][g_key]
                # mx_key = i_key
                mx_key = g_key # record mapping with greatest pixel count
        p += my_mx
        # L_sets.add(g_key)
        L_sets.add(mx_key) # add the g_key we consider to be correct
        # best[i_key] = g_key
        best[i_key] = mx_key # record &#34;true&#34; mapping
    L = len(L_sets)
    return total-p, L, best</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="see.Segment_Fitness.segment_fitness"><code class="flex name class">
<span>class <span class="ident">segment_fitness</span></span>
<span>(</span><span>paramlist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Contains functions to return result of fitness function.</p>
<p>and run segmentation algorithm</p>
<p>Generate algorithm params from parameter list.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class segment_fitness(algorithm):
    &#34;&#34;&#34;Contains functions to return result of fitness function.
    
    and run segmentation algorithm
    &#34;&#34;&#34;
    
    def __init__(self, paramlist=None):
        &#34;&#34;&#34;Generate algorithm params from parameter list.&#34;&#34;&#34;
        super(segment_fitness, self).__init__(paramlist)
        
    def evaluate(self, mask, gmask):
        &#34;&#34;&#34;Return result of fitness function with image and its ground truth.
           
        Keyword arguments: 
        mask -- the given image
        gmask -- the ground truth mask image
        &#34;&#34;&#34;        
        return FitnessFunction(mask, gmask)
        
    def pipe(self, data):
        &#34;&#34;&#34;Run segmentation algorithm to get inferred mask.&#34;&#34;&#34;
        data.fitness = self.evaluate(data.mask, data.gmask)[0]
        return data    </code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="see.Segment_Fitness.segment_fitness.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, mask, gmask)</span>
</code></dt>
<dd>
<div class="desc"><p>Return result of fitness function with image and its ground truth.</p>
<p>Keyword arguments:
mask &ndash; the given image
gmask &ndash; the ground truth mask image</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, mask, gmask):
    &#34;&#34;&#34;Return result of fitness function with image and its ground truth.
       
    Keyword arguments: 
    mask -- the given image
    gmask -- the ground truth mask image
    &#34;&#34;&#34;        
    return FitnessFunction(mask, gmask)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="see.base_classes.algorithm" href="base_classes.html#see.base_classes.algorithm">algorithm</a></b></code>:
<ul class="hlist">
<li><code><a title="see.base_classes.algorithm.algorithm_code" href="base_classes.html#see.base_classes.algorithm.algorithm_code">algorithm_code</a></code></li>
<li><code><a title="see.base_classes.algorithm.checkparamindex" href="base_classes.html#see.base_classes.algorithm.checkparamindex">checkparamindex</a></code></li>
<li><code><a title="see.base_classes.algorithm.mutateself" href="base_classes.html#see.base_classes.algorithm.mutateself">mutateself</a></code></li>
<li><code><a title="see.base_classes.algorithm.pipe" href="base_classes.html#see.base_classes.algorithm.pipe">pipe</a></code></li>
<li><code><a title="see.base_classes.algorithm.runAlgo" href="base_classes.html#see.base_classes.algorithm.runAlgo">runAlgo</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="see" href="index.html">see</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="see.Segment_Fitness.FF_Gamma" href="#see.Segment_Fitness.FF_Gamma">FF_Gamma</a></code></li>
<li><code><a title="see.Segment_Fitness.FF_Hamming" href="#see.Segment_Fitness.FF_Hamming">FF_Hamming</a></code></li>
<li><code><a title="see.Segment_Fitness.FF_ML2DHD" href="#see.Segment_Fitness.FF_ML2DHD">FF_ML2DHD</a></code></li>
<li><code><a title="see.Segment_Fitness.FF_ML2DHD_V2" href="#see.Segment_Fitness.FF_ML2DHD_V2">FF_ML2DHD_V2</a></code></li>
<li><code><a title="see.Segment_Fitness.FF_Normal" href="#see.Segment_Fitness.FF_Normal">FF_Normal</a></code></li>
<li><code><a title="see.Segment_Fitness.FF_Option1" href="#see.Segment_Fitness.FF_Option1">FF_Option1</a></code></li>
<li><code><a title="see.Segment_Fitness.FF_Option2a" href="#see.Segment_Fitness.FF_Option2a">FF_Option2a</a></code></li>
<li><code><a title="see.Segment_Fitness.FF_Option2b" href="#see.Segment_Fitness.FF_Option2b">FF_Option2b</a></code></li>
<li><code><a title="see.Segment_Fitness.FitnessFunction" href="#see.Segment_Fitness.FitnessFunction">FitnessFunction</a></code></li>
<li><code><a title="see.Segment_Fitness.FitnessFunction_old" href="#see.Segment_Fitness.FitnessFunction_old">FitnessFunction_old</a></code></li>
<li><code><a title="see.Segment_Fitness.countMatches" href="#see.Segment_Fitness.countMatches">countMatches</a></code></li>
<li><code><a title="see.Segment_Fitness.countsets" href="#see.Segment_Fitness.countsets">countsets</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="see.Segment_Fitness.segment_fitness" href="#see.Segment_Fitness.segment_fitness">segment_fitness</a></code></h4>
<ul class="">
<li><code><a title="see.Segment_Fitness.segment_fitness.evaluate" href="#see.Segment_Fitness.segment_fitness.evaluate">evaluate</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>